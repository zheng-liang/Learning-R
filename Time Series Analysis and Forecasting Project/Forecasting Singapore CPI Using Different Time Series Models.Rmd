---
title: "Forecasting Singapore's Consumer Price Index Using Different Time Series Models"
output:
  github_document:
    toc: true
---

# 1 Introduction

The purpose of this project is to introduce time series modelling and forecasting in R using a practical example. It covers the common tests that are done in time series analysis, such as unit root tests for stationarity, Breusch-Godfrey test for serial correlation, and Granger Causality test for determining whether variables are useful in forecasting other variables. The main models used in this project are the ARIMA, ARDL and VAR models, which will be discussed in detail in the later sections. However, I would not be tackling the issue of seasonality in this project as it will become a lengthy discussion. Instead, I would do this in a future project as I get familiar with the treatment of seasonal effects on time series and allow for comparison against the results I have documented here.

I attempted to forecast Singapore's Consumer Price Index (CPI) using the Producer Price Index (PPI) and the Composite Leading Index (CLI). The data used in this project was obtained from the Department of Statistics (DOS) Singapore and can be accessed from the [SingStat Table Builder](https://tablebuilder.singstat.gov.sg/). The data was imported via an API, but it can also be downloaded as an Excel or CSV file.

# 2 Packages Required

```{r load packages, message=FALSE}
# Use install.packages("packagename") if they are not already installed

# Packages that will be needed for obtaining data via an API
library(httr)
library(jsonlite)

# Packages that produces neat regression tables (only when possible)
library(broom)
library(knitr)
library(stargazer)

# Packages that will be needed for the main parts of the project
library(ARDL) # For ARDL models
library(bruceR) # For multivariate granger causality test
library(corrplot) # For visualizing correlation between variables
library(forecast) # For ARIMA models, forecasting and evaluation
library(lmtest) # For tests such as Breusch-Godfrey, Breusch-Pagan
library(lubridate) # For working with dates
library(tidyverse) # For ggplot2 and dplyr
library(urca) # For unit root tests
library(xts) # For converting data to and working with xts objects
library(vars) # For VAR models
```

# 3 Importing Data Using API

To import data using an API, we need to use the **`GET`** function in the `httr` package. We need to specify a URL to send a request for data retrieval. Websites that has an API usually has their own documentation on how to structure the parameters of the URL. For DOS Singapore, the documentation can be found [here](https://tablebuilder.singstat.gov.sg/view-api/for-developers).

I have included the process in detail for retrieving the "[Consumer Price Index, 2019 As Base Year](https://tablebuilder.singstat.gov.sg/table/TS/M212881)" data. For the rest of the variables, I would run the steps in a single R chunk for each variable.

```{r cpi url}
cpi_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M212881?isTestApi=true&seriesNoORrowNo=1"

raw_cpi <- httr::GET(url = cpi_url)
```

It has returned a list object which we can further explore by calling `raw_cpi`.

```{r explore rawdata}
raw_cpi

names(raw_cpi)

head(raw_cpi$content)
```

The `Status: 200` tells us that the operation was successful. If it returned the number 400 or 404, it would mean that there are errors in our query or the resource could not be found. The `Content-Type` tells us that the data takes on a JSON format, which is why the `jsonlite` package was needed.

Using the **`names`** function, we can find out what is in the `raw_cpi` list. The most important part we need is in the `content`, which is not useful until we convert it to text in a JSON format. To do this, we need the **`rawToChar`** in base R and **`fromJSON`** function in the `jsonlite` package.

```{r convert to text}
cpi <- jsonlite::fromJSON(rawToChar(raw_cpi$content))

names(cpi)

lapply(cpi, FUN = class)
```

Using the **`names`** function on the resulting `cpi` list, we can find the elements in the list and we are interested in the `Data` element. Using the **`lapply`** function and indicating **`FUN = class`**, it returned the classes of the elements in the list. Let us dig deeper into the `Data` element.

```{r data element}
names(cpi$Data)

names(cpi$Data$row)

head(lapply(cpi$Data$row$columns, head))
```

The `Data` list consists of the type of data and some of the values in each element. The elements `id`, `title`, `frequency`, etc. are the parameters or metadata from the API query. What we need is the `row` element. The `seriesNo` and `rowText`represents the class and sub-classes of items in the CPI basket, for example 1 refers to All Items, 1.0 refers to Food, and 1.1 refers to Food Excl Food Serving Services, etc. For our analysis, I am interested in the CPI - All Items, and due to a parameter in our URL specifying to only return the values under this category, we only have data for it as can be seen in the `columns` element. Due to the size of the `columns` list, I had to use the **`head`** function to simplify the output.

Working with list of lists can be troublesome, so it would a good idea to convert it into a data frame (at least for now).

```{r convert to df}
cpi_data <- as.data.frame(cpi$Data$row$columns[[1]])
```

Let us take a look at `cpi_data`.

```{r cpidata}
head(cpi_data, n = 4); tail(cpi_data, n = 4)
```

We can see that the order of the data is based on the time observations but on the character values of the dates. To reorder the observations, we can use the functions in the **`lubridate`** and **`dplyr`** packages.

```{r reordering date}
cpi_data <- cpi_data %>% 
  dplyr::arrange(lubridate::ym(cpi_data$key))

head(cpi_data, n = 4); tail(cpi_data, n = 4)
```

I have simplified the steps for data retrieval and conversion into data frame for the other variables of interest.

[Domestic Supply Price Index, By Commodity Section (1-Digit Level), Base Year 2018 = 100](https://tablebuilder.singstat.gov.sg/table/TS/M212701):

```{r dspi}
dspi_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M212701?isTestApi=true&seriesNoORrowNo=1"

raw_dspi <- httr::GET(url = dspi_url)

dspi <- jsonlite::fromJSON(rawToChar(raw_dspi$content))

dspi_data <- as.data.frame(dspi$Data$row$columns[[1]])

dspi_data <- dspi_data %>%
  dplyr::arrange(lubridate::ym(dspi_data$key))

head(dspi_data, n = 4); tail(dspi_data, n = 4)
```

[Composite Leading Index (2015 = 100)](https://tablebuilder.singstat.gov.sg/table/TS/M240421):

```{r cli}
cli_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M240421?isTestApi=true"

raw_cli <- httr::GET(url = cli_url)

cli <- jsonlite::fromJSON(rawToChar(raw_cli$content))

cli_data <- as.data.frame(cli$Data$row$columns[[1]])

# Data is ordered by the years and quarters so there was no need for reordering

head(cli_data, n = 4); tail(cli_data, n = 4)
```

# 4 Exploratory Data Analysis

In this section, I provided more details about each variable and generated univariate and multivariate plots to find patterns in and interaction between the variables. To visualize the plots, rather than using a data frame object, it is best to convert them into an `xts` object. The conversion requires two arguments. First is the vector or matrix to be converted to xts object and a vector of the date. We have the dates in the data frame but they are not formatted as dates, so I used the **`yearmon`** and **`yearqtr`** functions to format them to the appropriate types.

```{r convert df to xts}
cpi.xts <- xts(x = cpi_data$value, 
               order.by = as.yearmon(cpi_data$key, format = "%Y %b")) %>%
  `colnames<-`("CPI")

dspi.xts <- xts(x = dspi_data$value, 
                order.by = as.yearmon(dspi_data$key, format = "%Y %b")) %>%
  `colnames<-`("DSPI")

cli.xts <- xts(x = cli_data$value, 
               order.by = as.yearqtr(gsub("Q", "", cli_data$key), format = "%Y %q")) %>%
  `colnames<-`("CLI")
```

Since the values were stored as characters, I converted them to numeric so that it can be properly analyzed. Unlike the normal data frame, we cannot use **`as.numeric`** function to convert the variable type to numeric. Instead, we need to use **`storage.mode`**.

```{r convert value to numeric}
storage.mode(cpi.xts) <- "numeric"

storage.mode(dspi.xts) <- "numeric"

storage.mode(cli.xts) <- "numeric"
```

## 4.1 Consumer Price Index

One of the widely-known and most watched indicator is the CPI as it can be used to determine the general inflation in a country. Inflation basically refers to the increase in general price levels of goods and services. Deflation (or negative inflation) would mean that the general price level of goods and services has fallen. The CPI measures the average price level of a basket of goods and services consumed by households, and the basket of goods is updated every five years in Singapore to better reflect the changing consumption habits. Due to the importance of the indicator, many economists in government or private business settings attempt to forecast it to formulate economic policies or business/investment decisions.

`cpi.xts` contained 736 monthly observations from January 1961 to April

1.  However, I would need to adjust this variable as the Composite Leading Index starts from 1978 and it is a quarterly series. For time series analysis to work, we need the variables to have same time interval.

```{r convert cpi to qtrly}
cpi_q.xts <- xts::apply.quarterly(cpi.xts, FUN = mean)

# Changing the date index to an appropriate format
tclass(cpi_q.xts) <- "yearqtr"
```

```{r subset cpi_q}
#Subset cpi_q to match the cli data

cpi_q.xts <- cpi_q.xts["1978-01/2022-03"]
```

I have plotted the cleaned `cpi_q.xts`, which shows how the CPI has changed over time. We can see that the series is non-stationary, which could probably be solved by taking the first difference on the data. More about this in the next section.

```{r plot cpi}
plot.xts(cpi_q.xts, main = "Singapore Quarterly CPI from 1978Q1 to 2022Q1")
```

I have also generated a boxplot of the range of CPI values of all years grouped by the quarters. It is hard to say if there are any differences between the quarters to indicate an effect of seasonality. However, since the data obtained was not seasonally-adjusted, we might want to consider adding seasonal dummies to our time series model. However, since seasonality is not the main purpose of this project, we may treat this as a factor for discussion in future research.

```{r seasonality in cpi}
boxplot(cpi_q.xts ~ cycle(cpi_q.xts),
        ylab = "Quarterly CPI",
        xlab = "Quarters")
```

## 4.2 Domestic Supply Price Index

There are 3 different measurements of the PPI in Singapore, namely the Domestic Supply Price Index, the Singapore Manufactured Products Price Index and the Services Producer Price Index. Here are the descriptions of each index:

| Index | Description                                                                                                                                                                                                                                                             |
|-------------------|-----------------------------------------------------|
| DSPI  | Monitors the price changes of locally manufactured goods and imports which are retained for use in the domestic economy. It gives an indication of the price trends of goods used in the domestic economy.                                                              |
| SMPPI | Measures the changes in the prices of goods produced by manufacturers in Singapore for sale in the domestic and international markets.                                                                                                                                  |
| SPPI  | Contains indices of different services: Accounting Services Price Index, Cargo Handling Price Index, Computer Consultancy and Information Services Price Index, Freight Forwarding Price Index, Sea Freight Transport Price Index, Warehousing and Storage Price Index. |

The index I am interested in is the DSPI since it measures the prices of goods used in the domestic economy, including goods that were imported. It may give a better measure of the PPI, since these are the costs affecting the domestic manufacturers and would flow down the supply chain and affect the domestic end-consumers. We would expect that if PPI increases, CPI would increase as well.

Similar to `cpi.xts`, `dspi.xts` 580 monthly observations from January 1974 to April 2022. We would need to adjust the time interval to match the CLI data.

```{r convert and subset dspi qtrly}
dspi_q.xts <- xts::apply.quarterly(dspi.xts, FUN = mean)

tclass(dspi_q.xts) <- "yearqtr"

dspi_q.xts <- dspi_q.xts["1978-01/2022-03"]
```

Based on the plot of `dspi_q.xts`, the Singapore DSPI has ranged from a minimum of about 80 to a maximum of about 130. This is unlike the CPI chart that we saw earlier that had a clear upward trend.

```{r plot dspi}
plot.xts(dspi_q.xts, main = "Singapore Quarterly DSPI from 1978Q1 to 2022Q1")
```

Looking at the boxplot of the `dspi_q.xts` grouped by quarters, we can see some variation across quarters, which may indicate that seasonality is present. Based on the boxplot, the DSPI is generally lower in fourth quarter of each year than in other quarters.

```{r seasonality in dspi}
boxplot(dspi_q.xts ~ cycle(dspi_q.xts),
        ylab = "Quarterly DSPI",
        xlab = "Quarters")
```

## 4.3 Composite Leading Index

The CLI is a leading indicator to predict market expansions and slowdowns. It aggregates the following nine indicators:

-   Total New Companies Formed
-   Money Supply (M2)
-   Stock Exchange of Singapore Indices
-   Business Expectations for Wholesale Trade
-   Business Expectations for Stock of Finished Goods (Manufacturing)
-   US Purchasing Managersâ€™ Index (Manufacturing)
-   Total Non-oil Seaborne Cargo Handled
-   Domestic Liquidity Indicator
-   Total Non-oil Retained Imports

We could expect that if the CLI indicates a market upturn(downturn), CPI would increase(decrease).

```{r plot cli}
plot.xts(cli.xts, main = "Singapore Quarterly CLI from 1978Q1 to 2022Q1")
```

## 4.5 Multivariate Analysis

Before conducting a multivariate analysis, it would be better to merge our data into a single object. To do this, we need the **`merge`** function. However, as we can see there seems to be a problem, as there are two rows for each quarter in the year. This is because CPI and DSPI considered the quarter to be on March, June, September and December due to the adjustment we did previously.

```{r merge data}
data <- merge(cpi_q.xts, dspi_q.xts, cli.xts)

head(data)
```

To resolve this, we can use the **`na.locf`** function to replace the NAs with the last observation. We can do this on the column, and use the **`na.omit`** function to remove rows with NAs in the CPI and DSPI columns. This would remove the duplication of the quarters in each year.

```{r clean data}
data[, 3] <- na.locf(data[, 3])

data <- na.omit(data)

head(data); dim(data)
```

So now we have 177 quarterly observations and 4 variables, which is correct. I have plotted a scatterplot matrix of the variables in `data`. We can see a clear pattern between CPI and CLI, but not so with DSPI. However, this is because we could see a clear upward trend in CPI and CLI when plotted on a chart, but DSPI had a ranging pattern. The correlation matrix plot also shows how the variables are correlated.

```{r scatplot data}
pairs( ~ CPI + DSPI + CLI,
       data = data,
       lower.panel = NULL,
       main = "Scatterplot Matrix of CPI, DSPI and CLI")

```

```{r corrplot data}
correl <- cor(x = data, method = "spearman")

corrplot(correl,
         method = "color", 
         type = "lower", 
         addCoef.col = "black")
```

# 5 Splitting Data Into Training and Testing Sets.

Before we continue with any serious analysis, it would be better to split our data into training and testing sets. The training set will be used to create our models, while the testing set will be used to evaluate our models on out-of-sample prediction. Unlike cross-sectional data, the splitting of the data can only happen at a certain observation and not randomly selected to preserve the stochastic process of the observations.

```{r split data}
train <- data["/2019"]

test <- data["2019-12/"] # Need the last observation in 2019 so that when we difference the data, we can avoid the NAs
```

# 6 Unit Root Test for Stationarity

Now that we have a better understanding of our variables, we can proceed with the actual time series analysis. However, the first thing to do before modelling is to check that the variables are stationary.

Stationarity of variables is an important condition in most time series models as regression with non-stationary variables can lead to spurious results. Time series are said to be stationary if they have a constant mean, constant variance and the covariance between observations $h$ periods apart depends on $h$. This type of stationarity is called covariance (weak) stationarity.

A common test for stationarity is the Augmented Dickey-Fuller (ADF) unit root test. The null hypothesis claims that there is unit root in the series and hence it is non-stationary, while the alternative hypothesis claims that there is no unit root in the series. An alternative is the Phillips-Perron (PP) unit root test, which has the same null and alternative hypothesis as the ADF test. Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test is a test to check for the stationarity of time series variables. KPSS test is commonly used in conjunction with the ADF or PP test. The the hypotheses of KPSS test is opposite to that of ADF and PP test, with the null claiming that the time series is stationary with deterministic trend and the alternative claiming that it is not stationary.

If a series is non-stationary, it is common to take the first difference (i.e. $y_t$ - $y_{t-1}$) or to de-trend a trend stationary series. If a series is stationary after taking the first difference, we now have an I(1) series or we can say that the variable is integrated of order 1. The original series (or at levels) is I(0), if stationary.

I performed the ADF and KPSS test on the four variables in the `data` object, firstly on the variables at levels then at first differences, using the **`ur.df`** and **`ur.kpss`** function in the **`urca`** package.

```{r adf cpi level}
# Indicate type = "trend" as there was trend in the series based on plot
# Indicate selectlags = "AIC" to select lags based on Akaike IC

train$CPI %>%
  ur.df(type = "trend", selectlags = "AIC") %>%
  summary()
```

The **`summary`** function returns the full output of the ADF test, but we only need the bottom section where the test statistics and the critical values are. The first test statistic, for `tau2`, is higher than the 5% critical value (-2.042 > -3.43) but we need it to be lower than the critical value to reject the null (ADF is a one-sided test, where the alternative is < 0). Therefore, the CPI series contains unit root. The `phi3` value (third value in the test statistic) has the null hypothesis that there is unit root and no time trend (joint test). The `phi2` value (second value in the test statistic) has the null hypothesis that there is unit root, no drift and no time trend (joint test). We rejected `phi2` based on the 5% critical value, which means that either one, two or all three coefficients are not 0.

```{r kpss cpi level}
# Indicate type = "tau" for trend

train$CPI %>%
  ur.kpss(type = "tau" , lags = "short") %>%
  summary()
```

The KPSS test rejected the null hypothesis (test statistic 0.2947 > 5% critical value 0.146), which means there is unit root in the CPI series.

```{r adf dspi level}
# Indicate type = "drift" as DSPI as there is no particular long term trend

train$DSPI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

# Indicate type = "mu" for drift

train$DSPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

For the DSPI series, we can see contradicting results where the ADF test does not reject the null of unit root, but the KPSS test does not reject the null of stationarity. This may happen due to insufficient observations, but let us assume that there is unit root in this series.

```{r adf cli level}
# Indicate type = "trend"  since there was a clear trend in CLI plot

train$CLI %>%
  ur.df(type = "trend", selectlags = "AIC") %>%
  summary()

train$CLI %>%
  ur.kpss(type = "tau", lags = "short") %>%
  summary()
```

We rejected the null in the ADF test, and do not reject the null in the KPSS test. This indicated that CLI has a deterministic trend, which can be removed to make the series stationary. However, for simplicity sake, I would use the first difference (although there are arguments that this is incorrect and leads to spurious analysis).

```{r diff data}
# By default, the diff function uses lag = 1 and differences = 1

diff.train <- diff(train) %>%
  `colnames<-`(c("d.CPI", "d.DSPI", "d.CLI"))

head(diff.train) # First observation removed because we cannot take difference on it. 

diff.train <- na.omit(diff.train)
```

```{r plot diff data}
par(mfrow = c(2, 2))
for (i in 1:3) {
  print(plot.xts(diff.train[,i], main = names(diff.train[,i])))
}
```

The following R chunks performs the ADF test on the first-differenced variables. Because we have taken the first difference, there is no need to include trend option in ADF test.

```{r adf dcpi}
# After differencing, there should be no deterministic trend in the plots, but it may contain drift terms (especially dealing with non-zero means)
# KPSS test null hypothesis is that variables are stationary with deterministic parts, so just indicate type = "mu"

diff.train$d.CPI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

diff.train$d.CPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

```{r adf ddspi}
diff.train$d.DSPI %>%
  ur.df(type = "none", selectlags = "AIC") %>%
  summary()

diff.train$d.DSPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

```{r adf dcli}
diff.train$d.CLI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

diff.train$d.CLI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

Since the ADF tau-statistic for all variables are less than the critical tau-value, we can reject the null hypothesis and conclude that the series are I(1) variables (stationary at first difference).

After taking the first difference, we can see that the interaction between variables have changed in the scatterplot matrix and the correlation matrix.

```{r scatplot diff train}
pairs(~ d.CPI + d.DSPI + d.CLI, 
      data = diff.train,
      lower.panel = NULL,
      main = "Scatterplot Matrix of First Differenced Variables")
```

```{r corrplot diff train}
correldiff <- cor(diff.train, method = "spearman")

corrplot(correldiff,
         method = "color",
         type = "lower",
         addCoef.col = "black")
```

# 7 Model Selection

In this section, I discussed the different possible time series models that can be created from our data.

## 7.1 Autoregressive (Integrated) Moving Average Model

The AR(I)MA model consists of two parts, an autoregressive (AR) model and a moving average (MA) model. Integrated refers to the number of differencing needed to achieve stationary time series.

An AR(p) model means that $y_t$ depends on p lags of $y$. In other words, we believe that up to the $p$ historical value of $y$ can explain $y_t$. The function is written as:

$$
y_t = \alpha + \sum_{i = 1}^p \alpha_i y_{t-i} + u_t
$$

A MA(q) model means that $y_t$ depends on q lags of its error terms. In other words, we believe that up to $q$ historical value of $u$ (the error term) can explain $y_t$. The function is written as:

$$
y_t = \alpha + u_t + \sum_{j=1}^q \beta_j u_{t-j}
$$

An ARMA(p, q) model the combination of AR(p) and MA(q) models. The function is written as:

$$
y_t = \alpha + \sum_{i = 1}^p \alpha_i y_{t-i} + u_t + \sum_{j=1}^q \beta_j u_{t-j}
$$

This can be written simply as ARIMA(p, d, q). In Section 6, I had tested that the CPI series is an I(1) series, which means it is stationary at first difference. Therefore, we have an ARIMA(p, 1, q) model. The p and q lags are determined in various ways. Firstly, it is common to use the autocorrelation and partial autocorrelation function to determine the lag order. The functions **`Acf`** and **`Pacf`** in the **`forecast`** package can plot the ACF and PACF.

```{r acf pacf}
par(mfrow = c(2,1), mar = c(2, 2, 4, 2))

forecast::Acf(x = diff.train$d.CPI, main = "ACF of d.CPI")

forecast::Pacf(x = diff.train$d.CPI, main = "PACF of d.CPI")
```

We can gauge/estimate the q lags of the error term using the ACF where spikes are above the blue dotted line and similarly, p lags of the dependent variable using the PACF. Usually, the first spike in the ACF plot refers to lag 0, but the **`forecast`** package removes and we can use the first spike as lag 1 instead. In this case, we might want to try to fit a ARIMA(1, 1, 4) model using the **`Arima`** function in **`forecast`** package.

```{r arima114}
# order refers to the (p,d,q) of the ARIMA model
# d = 0 as we are using the differenced data
# method for estimation is to use maximum likelihood

arima1 <- forecast::Arima(diff.train$d.CPI, 
                          order = c(1, 0, 4),
                          method = "ML")

summary(arima1)
```

Another method that gets us the same results would be to use the data at levels but indicate `c(1, 1, 4)` in the `order` argument. The benefit of using this method is that the fitted values obtained from the model is automatically corrected to values at levels, instead of first difference. However, other functions used in further sections are based on differenced data as input since we cannot specify a differencing argument in the functions. Therefore, for better comparison, I have decided to use the differenced data here as well.

The output shows the coefficients of the lagged variables in the ARIMA model. It should be noted that the mean value is the mean of the series (not the sample mean, but calculated with the log-likelihood). To convert to the constant value, we multiply the mean by $(1-0.7090)$, which is basically coefficient of the AR terms.

We can write our model as:

$$
y_t = 0.097 + 0.7090y_{t-1} - 0.3086u_{t-1} - 0.0016u_{t-2} - 0.0469u_{t-3} + 0.0463u_{t-4}
$$

How well does our manually selected model compare against a model selected automatically using the lowest Akaike Information Criterion? We can estimate such a model using the **`auto.arima`** function. We have many arguments that we should include: `seasonal` should be set to False since I am not estimating a seasonal ARIMA, `stepwise` and `approximation` should be set to False to obtain a more accurate model selection, `ic` set to AIC, and `trace` set to False to suppress the running of the models by the automatic selection.

```{r auto arima}
arima2 <- forecast::auto.arima(diff.train$d.CPI, 
                               seasonal = F, 
                               ic = "aic", 
                               stepwise = F, 
                               approximation = F,
                               trace = F,
                               method = "ML")

summary(arima2)
```

We can see that the model automatically selected using the lowest AIC is the different from the one I had manually coded into the **`Arima`** function. The `arima2` model had a lower AIC and had a slightly higher log-likelihood than the `arima1` model. I plotted the actual CPI values and the fitted values based on the two ARIMA models to visualize how well the model fits.

```{r plot arima}
# indicated xlim to zoom into the chart to have a better view of the patterns
plot(ts(diff.train$d.CPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.CPI", main = "Actual vs Fitted CPI at First Difference Using ARIMA",
     xlim = c(1990, 2019))

lines(ts(fitted(arima1), start = c(1978, 2), frequency = 4), col = "red", type = "l", lwd = 3)

lines(ts(fitted(arima2), start = c(1978, 2), frequency = 4), col = "gray", type = "l", lwd = 3)

abline(h = arima2$coef[4], col = "black", lwd = 2)

legend(x = "topright", legend = c("Actual d.CPI", "arima1", "arima2", "Mean from arima2"),
       col = c("darkblue", "red", "gray", "black"), lwd = 1.5)
```

It seems that the `arima1` and `arima2` models approximately captures the pattern (with slight differences), although it does not seem to capture the magnitude of the movements in the CPI that well. ARIMA models can give us a benchmark to compare other types of time series models, either through in-sample prediction or out-of-sample forecast.

## 7.2 Autoregressive Distributed Lag Models

An ARDL model is similar to an ARMA model, except it used the lags of the dependent variables and lags of other explanatory variables to predict $y_t$. ARDL can be used on time series with combinations of I(0) and I(1).

The simplest ARDL model is one with an explanatory ($x$) and a dependent variable ($y$) and the notation for this is ARDL(p, q). Unlike the ARIMA models, an ARDL model allows us to capture the dynamic effects from $x$ to $y$. We can write the model as such:

$$
y_t = \alpha + \sum_{i=1}^p \alpha_i y_{t-i} + \sum_{j=0}^q \beta_i x_{t-i} + \epsilon_t
$$

In our case, we have more than 1 explanatory variables but the same concept applies. We can use the **`auto_ardl`** function in the **`ARDL`** package to automatically select an ARDL model that has the lowest AIC based on a maximum number of lags for the search.

```{r ardl1}
# max_order = 4 to indicate maximum lag in the search for all variables is 4
# possible to state a vector of length equal to no. of variables in max_order
# grid = T to to prevent stepwise search of models

ardl_lag <- ARDL::auto_ardl(formula = d.CPI ~ d.DSPI + d.CLI,
                            data = as.zoo(diff.train),
                            max_order = 4, grid = T,
                            selection = "AIC")

# Obtain the best lag order, arranged by how variables were entered in the formula argument
ardl_lag$best_order

# Save the best model selected by the auto ardl function
ardl <- ardl_lag$best_model

summary(ardl)
```

Unlike the ARIMA output earlier, the ARDL output does not state the log-likelihood or the AIC values. This can be found using the **`logLik`** and **`AIC`** functions in base R.

```{r loglik and aic}
logLik(ardl)

AIC(ardl)
```

The log-likelihood is much higher and AIC much lower than the `arima2` model estimated in Section 9.1, which should indicate a better fit.

```{r plot ardl}
plot.zoo(diff.train$d.CPI,
         col = "darkblue", type = "l", lwd = 3,
         ylab = "d.CPI", xlab = "Time",
         main = "Actual vs Fitted CPI at First Difference Using ARDL",
         xlim = c(1990, 2019))

lines(fitted(ardl), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CPI", "ardl"),
       col = c("darkblue", "red"), lwd = 1.5)
```

Notice that the x-axis has changed. This is because I used the **`plot.zoo`** function instead of **`plot`** since both `diff.train` and `fitted(ardl)` are technically `zoo` objects. The fitted values of `arima1` and `arima2` are `ts` objects and coercing them to `zoo` objects require more steps, which is not the purpose of this project.

We can see a significant improvement in the fit of the `ardl1` model as compared to the `arima2` model in Section 9.1.

## 7.3 Vector Autoregressive Model

A VAR model allows us to model the influence of two or more time series on one another, meaning that these variables are endogenous. In VAR models, the variables (e.g. $x$ and $y$) are simultaneously determined by the lags of these variables. A VAR(p) model of two variables can be written as:

$$ 
y_t = beta_{10} + beta_{11} y_{t-1} + dotsc + beta_{1p} y_{t-p} + gamma_{11} x_{t-1} + \dotsc + gamma_{1p} x_{t-p} + u_{1t} \\

x_t = beta_{20} + beta_{21} y_{t-1} + dotsc + beta_{2p} y_{t-p} + gamma_{21} x_{t-1} + \dotsc + gamma_{2p} x_{t-p} + u_{2t} 
$$

We can see that with more lags and more variables included into the VAR system, there would be more unknown parameters and lesser degrees of freedom, which can affect estimation and statistical tests. However, if too few lags were included, we may encounter the problem of autocorrelated errors.

To build a VAR model, we first need to determine the optimal number of lags which can be done by using the **`VARselect`** function in the **`vars`** package.

```{r var lag}
var_lag <- vars::VARselect(y = diff.train,
                           lag.max = 4,
                           type = "const")

var_lag
```

Based on AIC, I would choose to use 2 lag for the VAR model, i.e. VAR(2) model. We could use the SC (or BIC) selected lags for a parsimonious model. The function **`VAR`** in the **`vars`** package allows us to estimate this model.

```{r var}
var <- vars::VAR(y = diff.train,
                 p = 2,
                 type = "const")

stargazer(var$varresult, 
          type = "text", 
          title = "VAR Estimation Result for d.CPI, d.DSPI, d.CLI", 
          digits = 3, 
          column.labels = c("d.CPI", "d.DSPI", "d.CLI"),
          dep.var.labels.include = F)
```

The output shows the three equations, one for each variable, with 2 lags of each variable. Therefore, the model gets really big as more variables and lags are added, which can become a problem.

```{r plot var dcpi}
plot(ts(diff.train$d.CPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.CPI", xlab = "Time",
     main = "Actual vs Fitted CPI at First Difference Using VAR")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(var$varresult$d.CPI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CPI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

An advantage of models like VAR is that we can also plot the predicted values of other variables that are in the model.

```{r plot var ddspi}
plot(ts(diff.train$d.DSPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.DSPI", xlab = "Time",
     main = "Actual vs Fitted DSPI at First Difference Using VAR")

lines(ts(fitted(var$varresult$d.DSPI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.DSPI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot var dcli}
plot(ts(diff.train$d.CLI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.CLI", xlab = "Time",
     main = "Actual vs Fitted CLI at First Difference Using VAR")

lines(ts(fitted(var$varresult$d.CLI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CLI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

# 8 Granger Causality Test

Using the Granger Causality Test, we can statistically determine if a series can be used predict values of another series better than solely using its past values. Despite the name, it should not be used to determine true cause-and-effect relationships between variables. It can be a useful test to determine if variables should be added to a time series model to improve forecasting accuracy.

In simple terms, the Granger Causality Test checks if the lags of variable $x$ can be used to improve the forecast of variable 2 than solely basing on the lags of variable $y$. What the test does is to apply a Likelihood Ratio Test or a F-Test on the two models below. The null hypothesis is that $x$ does not granger-cause $y$, against the alternative that $x$ granger-causes $y$.

$$
\begin{aligned}
y_t &= \theta_0 + \theta_1 y_{t-1} + \gamma_1 x_{t-1} + e_t \\
y_t &= \theta_0 + \theta_1 y_{t-1} + e_t
\end{aligned}
$$

With two variables, we can test if $x$ granger-causes $y$, $y$ granger-causes $x$ or if there is bi-directional granger causality between $x$ and $y$. The set up would start to look like a VAR model, and there is indeed a package called **`bruceR`** that uses a VAR output to perform this test using the function **`granger_test`** for bivariate models and **`granger_causality`** for multivariate models.

```{r gc test}
granger_causality(varmodel = var)
```

The output provides both F-test and Likelihood Ratio Test values. Given the significance level of 5%, `d.DSPI` and `d.CLI` granger-cause `d.CPI` and `d.DSPI` granger-causes `d.CLI`. None of the variables granger-cause `d.DSPI` and we did not find any bi-directional causality. It may be that the wrong number of lags was chosen or simply that lags of other variables does not help in predicting other variables. In such cases, the forecasting power of this model may be affected since these variables are inter-dependent on one another.

# 9 Johansen Test for Cointegration

Since we have I(1) variables, we can model the variables at levels if they are found to have a cointegrating relationship. When variables are cointegrated, they appear to have the same long-run patterns and the difference between these two variables are stationary. In such cases, we could estimate a Error Correction Model (ECM) or a Vector Error Correction Model (VECM), which allows us to model long-run relationships between variables. If these I(1) variables are not cointegrated, we can only estimate a short-run model using the VAR or ARDL models.

To test for cointegration of multivariate time series, I have used the Johansen Test using the **`ca.jo`** function in the **`urca`** package. One of the arguments required is to specify the lag order of the level series in the VAR model. This can be determined using the **`VARselect`** function in the **`vars`** package.

```{r lag for jo test}
# Use the data at levels, not at first difference
lagselect <- vars::VARselect(train, lag.max = 4, type = "const")

lagselect$selection
```

To be constant throughout the project, I would use the AIC to select the number of lags. The `lagselect` output indicated we should use 3 lags for the Johansen Test.

```{r jo test trace}
# Indicate type = "trace" for trace test, "eigen" for eigenvalue test

# Indicate ecdet = "none" assuming no intercept in the cointegration process, indicate "const" or "trend" to add constant or trend into the equation

# K is the number of lags from the lag selection using VARselect

jotest <- urca::ca.jo(x = train, 
                      type = "trace", 
                      ecdet = "const", 
                      K = 3)

summary(jotest)
```

The test results are read starting from:

1.  r = 0: value under test column is more than value under 5pct column (statistically significant) and we have at least one cointegrating relationship.

2.  r <= 1: value under test column is more than value under 5pct column (statistically significant) and we have at least one cointegrating relationship.

3.  r <= 2: value under test column is less than value under 5pct column (statistically insignificant) and we have at most two cointegrating relationship.

Since we have found evidence of cointegration through the Johansen Test, we can estimate a ECM or VECM model.

## 9.1 Error Correction Model

Given the cointegration between variables, we can model the long-run equilibrium variable $y^*$ using the equilibrium of $x^*$ at levels. To model the short-run model, we need to remember that the variables are I(1), so we need to use a first-differenced equation, for example $\Delta y_t = \gamma_0 + \gamma_1 \Delta x_t + \epsilon_t$. But since there is a long-run association between $y$ and $x$, we could include some components into the short-run model so that it takes into account this long-run association. What we can add into the short-run model is the error correction term (ECT), which is the one-period ago residual from the long-run model. The following are the steps to modelling an ECM:

1. Regress $y^*$ on $x^*$ (and their lags) and obtain the residuals $v_t$
2. Regress $\Delta y_t$ on $\Delta x_t$ and the lag of the residual in Step 1, $v_{t-1}$

If there is indeed cointegration, the coefficient of $v_{t-1}$ should be between -1 and 0. This is because, taking the long-run pattern into account, if $y_{t-1}$ was above/below $y^*$, then we should expect $y_t$ to decrease/increase, showing an adjustment to the equilibrium. 

Let us first estimate a model in levels as per step one using **`auto_ardl`**

```{r ardl_lr}
ardl_lr_lag <- ARDL::auto_ardl(formula = CPI ~ DSPI + CLI,
                               data = as.zoo(train),
                               max_order = 4,
                               selection = "AIC",
                               grid = T)

ardl_lr <- ardl_lr_lag$best_model

summary(ardl_lr)
```

Instead of extracting the residuals, we can use the **`uecm`** and **`recm`** functions to get the unrestricted and restricted form of the ECM. The first model will show all the coefficients for the long-run and short-run variables, while the second will only show the short-run variables with the ECT.

```{r uecm}
un_ecm <- ARDL::uecm(ardl_lr)

summary(un_ecm)
```

`L(CPI, 1)` is the lag of our dependent variable and its coefficient is actually the ECT, which tells us how `CPI` would react given a shock to `L(CPI, 1)`. `L(DSPI, 1)` and `L(CLI, 1)` is the long-run coefficient (after some conversion) and the differenced variables (those starting with `d...`) are the short-run coefficients.

```{r recm}
# Indicated case = 3 to include constant in the model
r_ecm <- ARDL::recm(un_ecm, case = 3)

summary(r_ecm)
```

We can see that the `r_ecm` output is the same as the `un_ecm` output, less the long-run variables. And as expected, the ECT is negative and is between -1 and 0 (and statistically significant).

To obtain the long-run multiplier, we can use the **`multiplier`** function.

```{r lr multiplier}
multipliers(un_ecm) # Can also be used on ardl_lr
```

The equation of the error correction model is:

$$
\begin{aligned}

\Delta CPI_t = &-0.119 + 0.196\Delta CPI_{t-1} + 0.126\Delta CPI_{t-2} + 0.036\Delta DSPI_t \\
& + 0.018\Delta DSPI_{t-1} - 0.031\Delta CLI_{t} + 0.039\Delta CLI_{t-1} - 0.030ECT_{t-1}


\end{aligned}
$$

```{r plot ardl ecm}
plot.zoo(diff.train$d.CPI, col = "darkblue", type = "l", lwd = 3,
         ylab = "d.CPI", xlab = "Time",
         main = "Actual vs Fitted CPI at First Difference Using ARDL-ECM")

lines(fitted(r_ecm), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CPI", "ardl-ecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

## 9.2 Vector Error Correction Model

The VECM is simply a VAR model with error correction terms. What has been explained in Section 7.3 Vector Autoregressive Models and Section 9.1 Error Correction Model should be sufficient to give a glimpse of what a VECM is about. 

We can build a VECM using the **`urca`** package, using the functions **`ca.jo`**, **`cajools`** and **`cajorls`**. Although we had seen earlier in the Johansen Test that we used **`ca.jo`** to test the number of cointegrating relationships, it can also provide the VECM using the other functions mentioned.

```{r}
# K = 3 was determined in Section 9 in the Johansen Test
# Add in spec = "transitory" to obtain the VECM formula

get_vecm <- ca.jo(x = train, 
                  type = "trace", 
                  ecdet = "const", 
                  K = 3,
                  spec = "transitory")


# Get estimated VAR parameters
# r represents number of cointegrations

vec_ecm <- cajorls(get_vecm, r = 2)

kable(tidy(vec_ecm$rlm), format = "pipe",
      caption = "Estimates of 3-Equation Vector Error Correction Model",
      digits = 4)
```

The output shows the coefficients under the `estimate` column of each variable under the `term` column. The 3 equations in the VECM are:

$$
\begin{aligned}
\Delta CPI_t &= 0.189\Delta CPI_{t-1} + 0.165\Delta CPI_{t-2} + 0.032 \Delta DSPI_{t-1} -0.007\Delta DSPI_{t-2} \\
&~~~~
+0.021\Delta CLI_{t-1} + 0.015\Delta CLI_{t-2} -0.038ECT_{1, t-1} + 0.009ECT_{2,t-1} \\

\Delta DSPI_t &= -0.050\Delta CPI_{t-1} + 0.611\Delta CPI_{t-2} + 0.267\Delta DSPI_{t-1} -0.325\Delta DSPI_{t-2} \\
&~~~~
-0.125\Delta CLI_{t-1} + 0.208\Delta CLI_{t-2} -0.329ECT_{1, t-1} -0.032ECT_{2,t-1} \\

\Delta CLI_t &= -0.018\Delta CPI_{t-1} -0.358\Delta CPI_{t-2} -0.053\Delta DSPI_{t-1} -0.103\Delta DSPI_{t-2} \\
&~~~~
+0.366\Delta CLI_{t-1} -0.047\Delta CLI_{t-2} -0.021ECT_{1, t-1} + 0.016ECT_{2,t-1}

\end{aligned}
$$

```{r plot vecm cpi}
plot(ts(diff.train$d.CPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.CPI", xlab = "Time",
     main = "Actual vs Fitted CPI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"CPI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CPI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot vecm dspi}
plot(ts(diff.train$d.DSPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.DSPI", xlab = "Time",
     main = "Actual vs Fitted DSPI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"DSPI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.DSPI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot vecm cli}
plot(ts(diff.train$d.CLI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "d.CLI", xlab = "Time",
     main = "Actual vs Fitted CLI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"CLI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual d.CLI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

We can also convert the VECM in differences to a VAR in levels using the **`vec2var`** function, which is particularly useful when we are forecasting since it gives us the output in levels.

```{r vec2var}
var_ecm <- vec2var(get_vecm, r = 2)

(var_ecm)
```

# 10 Post-Estimation Tests

Two common problems encountered in time series analysis are serial correlation of errors and heteroskedastic errors. These can affect our analysis as estimators are no longer efficient and the usual test statistics become unreliable, which can be important if inference is the main purpose. The Breusch-Godfrey Test can be used to test for serial correlation, while the Breusch-Pagan Test can be used to test for heteroskedasticity. However, there is no single package that could accommodate different models for these tests, so we will have to use different functions from different packages for the models that are accepted.

However, using Newey-West standard errors to obtain the corrected test statistics regardless of whether serial correlation and/or heteroskedasticity is present seems to be an acceptable method, especially when we have large sample sizes.

## 10.1 ARDL Model

We can use the **`bgtest`** and **`bptest`** from the **`lmtest`** package.

```{r bg ardl}
# Test with up to 4 lags of the residuals

lmtest::bgtest(ardl, order = 4)
```

```{r bp ardl}
lmtest::bptest(ardl, studentize = T)
```

There is serial correlation and heteroskedasticity in the ARDL residuals, and we should use the Newey-West (Heteroskedasticity and Autocorrelation Corrected) standard errors to obtain the correct test statistics for inference.

## 10.2 VAR Model

The functions that can be applied to VAR models are **`serial.test`** and the **`arch.test`** from the **`vars`** package. The **`arch.test`** performs the ARCH test to detect if there is changing conditional variance in a time series, unlike the Breusch-Pagan test that detects for constant variance.

```{r bg var}
vars::serial.test(var, lags.bg = 4, type = "BG")
```

```{r arch var}
vars::arch.test(var, lags.single = 4, lags.multi = 4, multivariate.only = F)
```

From the tests, there are was no serial correlation detected at up to 4 lags of the error term, and only `d.CPI` and the overall VAR models has ARCH effects. 

## 10.3 VECM

```{r bg vecm}
vars::serial.test(var_ecm, lags.bg = 4, type = "BG")
```

```{r arch vecm}
vars::arch.test(var_ecm, lags.single = 4, lags.multi = 4, multivariate.only = F)
```

Similar to the tests for the VAR model, there is no serial correlation detected at up to 4 lags of the error terms and only the `CPI` single equation and the multivariate model has ARCH effects. 

# 11 Forecasting and Evaluation

For the forecast and evaluation, I would compare to the data at levels in the `test` dataset. I would forecast 4 periods and 8 periods ahead, to test the forecasting power of the different models at different lengths of time. However, there are two points to keep in mind. 

Firstly, the models were built using first-differenced data, so we will need to convert it back to levels after forecasting. This can be done easily by taking the last observation from the `train` dataset and adding the forecasting values. The only exception would be the `vec_ecm` model, which requires conversion to the VAR in levels (`var_ecm` model) so that it can be forecasted. 

Secondly, models such as ARIMA and VAR uses endogenous variable but ARDL models contains exogenous variables. This means that we would need data on the exogenous variables in the ARDL models for the forecasting to work. This can be done through the use of ARIMA models to predict exogenous variables before inputting them into the ARDL forecast. However, for simplicity, I would use the data in the `test` set to compare the performance of the ARDL and ARDL-EC models while ARIMA and VAR/VECM would be compared to one another.

The forecast can be obtained using the **`predict`** function from base R, which requires the number of steps ahead to forecast and new data if needed, such as for the ARDL models. THe **`forecast`** function from the **`forecast`** package can also do the same, but it does not seem to work with VAR models.

I have created the first-differenced test dataset in the R chunk below, which is the new data required for forecasting ARDL models.

```{r diff test}
diff.test <- diff(test) %>% na.omit()

diff.test
```






# References






