---
title: "Forecasting Singapore's Consumer Price Index Using Different Time Series Models"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

## 1 Introduction

The purpose of this project is to introduce time series modelling and forecasting in R using a practical example. It covers the common tests that are done in time series analysis, such as unit root tests for stationarity, Breusch-Godfrey test for serial correlation, and Granger Causality test for determining whether variables are useful in forecasting other variables. The main models used in this project are the ARIMA, ARDL and VAR models, which will be discussed in detail in the later sections. However, I would not be tackling the issue of seasonality in this project as it will become a lengthy discussion. Instead, I would do this in a future project as I get more familiar with the treatment of seasonal effects on time series and compare the results against the ones I have documented here.

I attempted to forecast Singapore's Consumer Price Index (CPI) using the Producer Price Index (PPI) and the Composite Leading Index (CLI). The data used in this project was obtained from the Department of Statistics (DOS) Singapore and can be accessed from the [SingStat Table Builder](https://tablebuilder.singstat.gov.sg/). The data was imported via an API, but it can also be downloaded as an Excel or CSV file.

## 2 Packages Required

```{r load packages, message=FALSE, warning=FALSE, results="hide", class.source = "fold-show"}
# Use install.packages("packagename") if they are not already installed

# Packages that will be needed for obtaining data via an API
library(httr)
library(jsonlite)

# Packages that produces neat regression tables (only when possible)
library(broom)
library(knitr)
library(stargazer)

# Packages that will be needed for the main parts of the project
library(ARDL) # For ARDL models lag selection
library(bruceR) # For multivariate granger causality test
library(corrplot) # For visualizing correlation between variables
library(dLagM) # For creating ARDL objects that can work with a forecast function
library(forecast) # For ARIMA models, forecasting and evaluation
library(lmtest) # For tests such as Breusch-Godfrey, Breusch-Pagan
library(lubridate) # For working with dates
library(tidyverse) # For ggplot2 and dplyr
library(urca) # For unit root tests
library(xts) # For converting data to and working with xts objects
library(vars) # For VAR models
```

## 3 Importing Data Using API

To import data using an API, we need to use the **`GET`** function in the `httr` package. We need to specify a URL to send a request for data retrieval. Websites that has an API usually has their own documentation on how to structure the parameters of the URL. For DOS Singapore, the documentation can be found [here](https://tablebuilder.singstat.gov.sg/view-api/for-developers).

I have included the process in detail for retrieving the "[Consumer Price Index, 2019 As Base Year](https://tablebuilder.singstat.gov.sg/table/TS/M212881)" data. For the rest of the variables, I would run the steps in a single R chunk for each variable.

```{r cpi url}
cpi_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M212881?isTestApi=true&seriesNoORrowNo=1"

raw_cpi <- httr::GET(url = cpi_url)
```

It has returned a list object which we can further explore by calling `raw_cpi`.

```{r explore rawdata}
raw_cpi

names(raw_cpi)

head(raw_cpi$content)
```

The `Status: 200` tells us that the operation was successful. If it returned the number 400 or 404, it would mean that there are errors in our query or the resource could not be found. The `Content-Type` tells us that the data takes on a JSON format, which is why the `jsonlite` package was needed.

Using the **`names`** function, we can find out what is in the `raw_cpi` list. The most important part we need is in the `content`, which is not useful until we convert it to text in a JSON format. To do this, we need the **`rawToChar`** in base R and **`fromJSON`** function in the `jsonlite` package.

```{r convert to text}
cpi <- jsonlite::fromJSON(rawToChar(raw_cpi$content))

names(cpi)

lapply(cpi, FUN = class)
```

Using the **`names`** function on the resulting `cpi` list, we can find the elements in the list and we are interested in the `Data` element. Using the **`lapply`** function and indicating **`FUN = class`**, it returned the classes of the elements in the list. Let us dig deeper into the `Data` element.

```{r data element}
names(cpi$Data)

names(cpi$Data$row)

head(lapply(cpi$Data$row$columns, dim))
```

The `Data` list consists of the type of data and some of the values in each element. The elements `id`, `title`, `frequency`, etc. are the parameters or metadata from the API query. What we need is the `row` element. The `seriesNo` and `rowText`represents the class and sub-classes of items in the CPI basket, for example 1 refers to All Items, 1.0 refers to Food, and 1.1 refers to Food Excl Food Serving Services, etc. For our analysis, I am interested in the CPI - All Items, and due to a parameter in our URL specifying to only return the values under this category, we only have data for it as can be seen in the `columns` element. Due to the size of the `columns` list, I had to use the **`head`** function to simplify the output.

Working with list of lists can be troublesome, so it would a good idea to convert it into a data frame (at least for now).

```{r convert to df}
cpi_data <- as.data.frame(cpi$Data$row$columns[[1]])
```

Let us take a look at `cpi_data`.

```{r cpidata}
stargazer(rbind(head(cpi_data, n = 8), tail(cpi_data, n = 8)),
          type = "text",
          title = "First and Last 8 Values in cpi data",
          summary = F)
```

We can see that the order of the data is based on the time observations but on the character values of the dates. To reorder the observations, we can use the functions in the **`lubridate`** and **`dplyr`** packages.

```{r reordering date}
cpi_data <- cpi_data %>% 
  dplyr::arrange(lubridate::ym(cpi_data$key))

stargazer(rbind(head(cpi_data, n = 8), tail(cpi_data, n = 8)),
          type = "text",
          title = "Adjusted First and Last 8 Values in cpi data",
          summary = F)
```

I have simplified the steps for data retrieval and conversion into data frame for the other variables of interest.

[Domestic Supply Price Index, By Commodity Section (1-Digit Level), Base Year 2018 = 100](https://tablebuilder.singstat.gov.sg/table/TS/M212701):

```{r dspi}
dspi_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M212701?isTestApi=true&seriesNoORrowNo=1"

raw_dspi <- httr::GET(url = dspi_url)

dspi <- jsonlite::fromJSON(rawToChar(raw_dspi$content))

dspi_data <- as.data.frame(dspi$Data$row$columns[[1]])

dspi_data <- dspi_data %>%
  dplyr::arrange(lubridate::ym(dspi_data$key))

stargazer(rbind(head(dspi_data, n = 8), tail(dspi_data, n = 8)),
          type = "text",
          title = "Adjusted First and Last 8 Values in dspi data",
          summary = F)
```

[Composite Leading Index (2015 = 100)](https://tablebuilder.singstat.gov.sg/table/TS/M240421):

```{r cli}
cli_url <- "https://tablebuilder.singstat.gov.sg/api/table/tabledata/M240421?isTestApi=true"

raw_cli <- httr::GET(url = cli_url)

cli <- jsonlite::fromJSON(rawToChar(raw_cli$content))

cli_data <- as.data.frame(cli$Data$row$columns[[1]])

# Data is ordered by the years and quarters so there was no need for reordering

stargazer(rbind(head(cli_data, n = 8), tail(cli_data, n = 8)),
          type = "text",
          title = "First and Last 8 Values in cli data",
          summary = F)
```

## 4 Exploratory Data Analysis

In this section, I provided more details about each variable and generated univariate and multivariate plots to find patterns in and interaction between the variables. To visualize the plots, rather than using a data frame object, it is best to convert them into an `xts` object. The conversion requires two arguments. First is the vector or matrix to be converted to xts object and a vector of the date. We have the dates in the data frame but they are not formatted as dates, so I used the **`yearmon`** and **`yearqtr`** functions to format them to the appropriate types.

```{r convert df to xts}
cpi.xts <- xts(x = cpi_data$value, 
               order.by = as.yearmon(cpi_data$key, format = "%Y %b")) %>%
  `colnames<-`("CPI")

dspi.xts <- xts(x = dspi_data$value, 
                order.by = as.yearmon(dspi_data$key, format = "%Y %b")) %>%
  `colnames<-`("DSPI")

cli.xts <- xts(x = cli_data$value, 
               order.by = as.yearqtr(gsub("Q", "", cli_data$key), format = "%Y %q")) %>%
  `colnames<-`("CLI")
```

Since the values were stored as characters, I converted them to numeric so that it can be properly analyzed. Unlike the normal data frame, we cannot use **`as.numeric`** function to convert the variable type to numeric. Instead, we need to use **`storage.mode`**.

```{r convert value to numeric}
storage.mode(cpi.xts) <- "numeric"

storage.mode(dspi.xts) <- "numeric"

storage.mode(cli.xts) <- "numeric"
```

### 4.1 Consumer Price Index

One of the widely-known and most watched indicator is the CPI as it can be used to determine the general inflation in a country. Inflation basically refers to the increase in general price levels of goods and services. Deflation (or negative inflation) would mean that the general price level of goods and services has fallen. The CPI measures the average price level of a basket of goods and services consumed by households, and the basket of goods is updated every five years in Singapore to better reflect the changing consumption habits. Due to the importance of the indicator, many economists in government or private business settings attempt to forecast it to formulate economic policies or business/investment decisions.

`cpi.xts` contained 736 monthly observations from January 1961 to April

1.  However, I would need to adjust this variable as the Composite Leading Index starts from 1978 and it is a quarterly series. For time series analysis to work, we need the variables to have same time interval.

```{r convert cpi to qtrly}
cpi_q.xts <- xts::apply.quarterly(cpi.xts, FUN = mean)

# Changing the date index to an appropriate format
tclass(cpi_q.xts) <- "yearqtr"
```

```{r subset cpi_q}
#Subset cpi_q to match the cli data

cpi_q.xts <- cpi_q.xts["1978-01/2022-03"]
```

I have plotted the cleaned `cpi_q.xts`, which shows how the CPI has changed over time. We can see that the series is non-stationary, which could probably be solved by taking the first difference on the data. More about this in the next section.

```{r plot cpi, fig.align='center', echo=FALSE}
plot.xts(cpi_q.xts, main = "Singapore Quarterly CPI from 1978Q1 to 2022Q1")
```

I have also generated a boxplot of the range of CPI values of all years grouped by the quarters. It is hard to say if there are any differences between the quarters to indicate an effect of seasonality. However, since the data obtained was not seasonally-adjusted, we might want to consider adding seasonal dummies to our time series model. However, since seasonality is not the main purpose of this project, we may treat this as a factor for discussion in future research.

```{r seasonality in cpi, fig.align='center', echo=FALSE}
boxplot(cpi_q.xts ~ cycle(cpi_q.xts),
        ylab = "Quarterly CPI",
        xlab = "Quarters")
```

### 4.2 Domestic Supply Price Index

There are 3 different measurements of the PPI in Singapore, namely the Domestic Supply Price Index, the Singapore Manufactured Products Price Index and the Services Producer Price Index. Here are the descriptions of each index:

| Index | Description                                                                                                                                                                                                                                                             |
|-------------------|-----------------------------------------------------|
| DSPI  | Monitors the price changes of locally manufactured goods and imports which are retained for use in the domestic economy. It gives an indication of the price trends of goods used in the domestic economy.                                                              |
| SMPPI | Measures the changes in the prices of goods produced by manufacturers in Singapore for sale in the domestic and international markets.                                                                                                                                  |
| SPPI  | Contains indices of different services: Accounting Services Price Index, Cargo Handling Price Index, Computer Consultancy and Information Services Price Index, Freight Forwarding Price Index, Sea Freight Transport Price Index, Warehousing and Storage Price Index. |

The index I am interested in is the DSPI since it measures the prices of goods used in the domestic economy, including goods that were imported. It may give a better measure of the PPI, since these are the costs affecting the domestic manufacturers and would flow down the supply chain and affect the domestic end-consumers. We would expect that if PPI increases, CPI would increase as well.

Similar to `cpi.xts`, `dspi.xts` 580 monthly observations from January 1974 to April 2022. We would need to adjust the time interval to match the CLI data.

```{r convert and subset dspi qtrly}
dspi_q.xts <- xts::apply.quarterly(dspi.xts, FUN = mean)

tclass(dspi_q.xts) <- "yearqtr"

dspi_q.xts <- dspi_q.xts["1978-01/2022-03"]
```

Based on the plot of `dspi_q.xts`, the Singapore DSPI has ranged from a minimum of about 80 to a maximum of about 130. This is unlike the CPI chart that we saw earlier that had a clear upward trend.

```{r plot dspi, fig.align='center', echo=FALSE}
plot.xts(dspi_q.xts, main = "Singapore Quarterly DSPI from 1978Q1 to 2022Q1")
```

Looking at the boxplot of the `dspi_q.xts` grouped by quarters, we can see some variation across quarters, which may indicate that seasonality is present. Based on the boxplot, the DSPI is generally lower in fourth quarter of each year than in other quarters.

```{r seasonality in dspi, fig.align='center', echo=FALSE}
boxplot(dspi_q.xts ~ cycle(dspi_q.xts),
        ylab = "Quarterly DSPI",
        xlab = "Quarters")
```

### 4.3 Composite Leading Index

The CLI is a leading indicator to predict market expansions and slowdowns. It aggregates the following nine indicators:

-   Total New Companies Formed
-   Money Supply (M2)
-   Stock Exchange of Singapore Indices
-   Business Expectations for Wholesale Trade
-   Business Expectations for Stock of Finished Goods (Manufacturing)
-   US Purchasing Managers’ Index (Manufacturing)
-   Total Non-oil Seaborne Cargo Handled
-   Domestic Liquidity Indicator
-   Total Non-oil Retained Imports

We could expect that if the CLI indicates a market upturn(downturn), CPI would increase(decrease).

```{r plot cli, fig.align='center', echo=FALSE}
plot.xts(cli.xts, main = "Singapore Quarterly CLI from 1978Q1 to 2022Q1")
```

### 4.5 Multivariate Analysis

Before conducting a multivariate analysis, it would be better to merge our data into a single object. To do this, we need the **`merge`** function. However, as we can see there seems to be a problem, as there are two rows for each quarter in the year. This is because CPI and DSPI considered the quarter to be on March, June, September and December due to the adjustment we did previously.

```{r merge data}
data <- merge(cpi_q.xts, dspi_q.xts, cli.xts)

stargazer(head(data, n = 8),
          type = "text",
          title = "Unadjusted data",
          rownames = T)
```

To resolve this, we can use the **`na.locf`** function to replace the NAs with the last observation. We can do this on the column, and use the **`na.omit`** function to remove rows with NAs in the CPI and DSPI columns. This would remove the duplication of the quarters in each year.

```{r clean data}
data[, 3] <- na.locf(data[, 3])

data <- na.omit(data)

stargazer(head(data, n = 8),
          type = "text",
          title = "Adjusted data",
          rownames = T)

dim(data)
```

So now we have 177 quarterly observations and 4 variables, which is correct. I have plotted a scatterplot matrix of the variables in `data`. We can see a clear pattern between CPI and CLI, but not so with DSPI. However, this is because we could see a clear upward trend in CPI and CLI when plotted on a chart, but DSPI had a ranging pattern. The correlation matrix plot also shows how the variables are correlated.

```{r scatplot data, fig.align='center', echo=FALSE}
pairs( ~ CPI + DSPI + CLI,
       data = data,
       lower.panel = NULL,
       main = "Scatterplot Matrix of CPI, DSPI and CLI")
```

```{r corrplot data, fig.align='center', echo=FALSE}
correl <- cor(x = data)

corrplot(correl,
         method = "color", 
         type = "lower", 
         addCoef.col = "black", 
         title = "Correlation Matrix of CPI, DSPI and CLI",
         mar = c(0, 0, 1, 0))
```

## 5 Splitting Data Into Training and Testing Sets.

Before we continue with any serious analysis, it would be better to split our data into training and testing sets. The training set will be used to create our models, while the testing set will be used to evaluate our models on out-of-sample prediction. Unlike cross-sectional data, the splitting of the data can only happen at a certain observation and not randomly selected to preserve the stochastic process of the observations.

```{r split data}
train <- data["/2019"]

test <- data["2020/"]
```

## 6 Unit Root Test for Stationarity

Now that we have a better understanding of our variables, we can proceed with the actual time series analysis. However, the first thing to do before modelling is to check that the variables are stationary.

Stationarity of variables is an important condition in most time series models as regression with non-stationary variables can lead to spurious results. Time series are said to be stationary if they have a constant mean, constant variance and the covariance between observations $h$ periods apart depends on $h$. This type of stationarity is called covariance (weak) stationarity.

A common test for stationarity is the Augmented Dickey-Fuller (ADF) unit root test. The null hypothesis claims that there is unit root in the series and hence it is non-stationary, while the alternative hypothesis claims that there is no unit root in the series. An alternative is the Phillips-Perron (PP) unit root test, which has the same null and alternative hypothesis as the ADF test. Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test is a test to check for the stationarity of time series variables. KPSS test is commonly used in conjunction with the ADF or PP test. The the hypotheses of KPSS test is opposite to that of ADF and PP test, with the null claiming that the time series is stationary with deterministic trend and the alternative claiming that it is not stationary.

If a series is non-stationary, it is common to take the first difference (i.e. $y_t$ - $y_{t-1}$) or to de-trend a trend stationary series. If a series is stationary after taking the first difference, we now have an I(1) series or we can say that the variable is integrated of order 1. The original series (or at levels) is I(0), if stationary.

I performed the ADF and KPSS test on the four variables in the `data` object, firstly on the variables at levels then at first differences, using the **`ur.df`** and **`ur.kpss`** function in the **`urca`** package.

```{r adf cpi level}
# Indicate type = "trend" as there was trend in the series based on plot
# Indicate selectlags = "AIC" to select lags based on Akaike IC

train$CPI %>%
  ur.df(type = "trend", selectlags = "AIC") %>%
  summary()
```

The **`summary`** function returns the full output of the ADF test, but we only need the bottom section where the test statistics and the critical values are. The first test statistic, for `tau3`, is higher than the 5% critical value (-2.042 > -3.43) but we need it to be lower than the critical value to reject the null (ADF is a one-sided test, where the alternative is < 0). Therefore, the CPI series contains unit root. The `phi3` value (third value in the test statistic) has the null hypothesis that there is unit root and no time trend (joint test). The `phi2` value (second value in the test statistic) has the null hypothesis that there is unit root, no drift and no time trend (joint test). We rejected `phi2` based on the 5% critical value, which means that either one, two or all three coefficients are not 0.

```{r kpss cpi level}
# Indicate type = "tau" for trend

train$CPI %>%
  ur.kpss(type = "tau" , lags = "short") %>%
  summary()
```

The KPSS test rejected the null hypothesis (test statistic 0.2947 > 5% critical value 0.146), which means there is unit root in the CPI series.

```{r adf dspi level}
# Indicate type = "drift" as DSPI as there is no particular long term trend

train$DSPI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

# Indicate type = "mu" for drift

train$DSPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

For the DSPI series, we can see contradicting results where the ADF test does not reject the null of unit root, but the KPSS test does not reject the null of stationarity. This may happen due to insufficient observations, but let us assume that there is unit root in this series.

```{r adf cli level}
# Indicate type = "trend"  since there was a clear trend in CLI plot

train$CLI %>%
  ur.df(type = "trend", selectlags = "AIC") %>%
  summary()

train$CLI %>%
  ur.kpss(type = "tau", lags = "short") %>%
  summary()
```

We rejected the null in the ADF test, and do not reject the null in the KPSS test. This indicated that CLI has a deterministic trend, which can be removed to make the series stationary. However, for simplicity sake, I would use the first difference (although there are arguments that this is incorrect and leads to spurious analysis).

```{r diff data}
# By default, the diff function uses lag = 1 and differences = 1

diff.data <- diff(data) %>%
  `colnames<-`(c("dCPI", "dDSPI", "dCLI"))

head(diff.data) # First observation removed because we cannot take difference on it. 

diff.data <- na.omit(diff.data)

# Split the train and test sets again

diff.train <- diff.data["/2019"]

diff.test <- diff.data["2020/"]
```

I plotted the variables after taking the first difference down below. We can see that there are no obvious trends or patterns in the plots after differencing.

```{r plot diff data, fig.align='center', echo=FALSE}
par(mfrow = c(2, 2))
for (i in 1:3) {
  print(plot.xts(diff.train[,i], main = names(diff.train[,i])))
}
```

The following R chunks performs the ADF test on the first-differenced variables. Because we have taken the first difference, there is no need to include trend option in ADF test.

```{r adf dcpi}
# After differencing, there should be no deterministic trend in the plots, but it may contain drift terms (especially dealing with non-zero means)
# KPSS test null hypothesis is that variables are stationary with deterministic parts, so just indicate type = "mu"

diff.train$dCPI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

diff.train$dCPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

```{r adf ddspi}
diff.train$dDSPI %>%
  ur.df(type = "none", selectlags = "AIC") %>%
  summary()

diff.train$dDSPI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

```{r adf dcli}
diff.train$dCLI %>%
  ur.df(type = "drift", selectlags = "AIC") %>%
  summary()

diff.train$dCLI %>%
  ur.kpss(type = "mu", lags = "short") %>%
  summary()
```

Since the ADF tau-statistic for all variables are less than the critical tau-value, we can reject the null hypothesis and conclude that the series are I(1) variables (stationary at first difference).

After taking the first difference, we can see that the interaction between variables have changed in the scatterplot matrix and the correlation matrix. This is why stationarity is an important condition as variables may seem to have a relationship at levels but after taking the difference, there may not be a relationship between variables as seen in the scatter plot below.

```{r scatplot diff train, fig.align='center', echo=FALSE}
pairs(~ dCPI + dDSPI + dCLI, 
      data = diff.train,
      lower.panel = NULL,
      main = "Scatterplot Matrix of First Differenced Variables")
```

```{r corrplot diff train, fig.align='center', echo=FALSE}
correldiff <- cor(diff.train)

corrplot(correldiff,
         method = "color",
         type = "lower",
         addCoef.col = "black",
         title = "Correlation Matrix of First Differenced Variables",
         mar = c(0, 0, 1, 0))
```

## 7 Model Selection

In this section, I discussed the different possible time series models that can be created from our data.

### 7.1 Autoregressive (Integrated) Moving Average Model

The AR(I)MA model consists of two parts, an autoregressive (AR) model and a moving average (MA) model. Integrated refers to the number of differencing needed to achieve stationary time series.

An AR(p) model means that $y_t$ depends on p lags of $y$. In other words, we believe that up to the $p$ historical value of $y$ can explain $y_t$. The function is written as:

$$
y_t = \alpha + \sum_{i = 1}^p \alpha_i y_{t-i} + u_t
$$

A MA(q) model means that $y_t$ depends on q lags of its error terms. In other words, we believe that up to $q$ historical value of $u$ (the error term) can explain $y_t$. The function is written as:

$$
y_t = \alpha + u_t + \sum_{j=1}^q \beta_j u_{t-j}
$$

An ARMA(p, q) model the combination of AR(p) and MA(q) models. The function is written as:

$$
y_t = \alpha + \sum_{i = 1}^p \alpha_i y_{t-i} + u_t + \sum_{j=1}^q \beta_j u_{t-j}
$$

This can be written simply as ARIMA(p, d, q). In Section 6, I had tested that the CPI series is an I(1) series, which means it is stationary at first difference. Therefore, we have an ARIMA(p, 1, q) model. The p and q lags are determined in various ways. Firstly, it is common to use the autocorrelation and partial autocorrelation function to determine the lag order. The functions **`Acf`** and **`Pacf`** in the **`forecast`** package can plot the ACF and PACF.

```{r acf pacf, fig.align='center'}
par(mfrow = c(2,1), mar = c(3, 3, 4, 2))

forecast::Acf(x = diff.train$dCPI, main = "ACF of dCPI")

forecast::Pacf(x = diff.train$dCPI, main = "PACF of dCPI")
```

We can gauge/estimate the q lags of the error term using the ACF where spikes are above the blue dotted line and similarly, p lags of the dependent variable using the PACF. Usually, the first spike in the ACF plot refers to lag 0, but the **`forecast`** package removes and we can use the first spike as lag 1 instead. In this case, we might want to try to fit a ARIMA(1, 1, 4) model using the **`Arima`** function in **`forecast`** package.

```{r arima114}
# order refers to the (p,d,q) of the ARIMA model
# d = 0 as we are using the differenced data
# method for estimation is to use maximum likelihood

arima1 <- forecast::Arima(diff.train$dCPI, 
                          order = c(1, 0, 4),
                          method = "ML")

summary(arima1)
```

Another method that gets us the same results would be to use the data at levels but indicate `c(1, 1, 4)` in the `order` argument. The benefit of using this method is that the fitted values obtained from the model is automatically corrected to values at levels, instead of first difference. However, other functions used in further sections are based on differenced data as input since we cannot specify a differencing argument in the functions. Therefore, for better comparison, I have decided to use the differenced data here as well.

The output shows the coefficients of the lagged variables in the ARIMA model. It should be noted that the mean value is the mean of the series (not the sample mean, but calculated with the log-likelihood). To convert to the constant value, we multiply the mean by $(1-0.7090)$, which is basically coefficient of the AR terms.

We can write our model as:

$$
y_t = 0.097 + 0.7090y_{t-1} - 0.3086u_{t-1} - 0.0016u_{t-2} - 0.0469u_{t-3} + 0.0463u_{t-4}
$$

How well does our manually selected model compare against a model selected automatically using the lowest Akaike Information Criterion? We can estimate such a model using the **`auto.arima`** function. We have many arguments that we should include: `seasonal` should be set to False since I am not estimating a seasonal ARIMA, `stepwise` and `approximation` should be set to False to obtain a more accurate model selection, `ic` set to AIC, and `trace` set to False to suppress the running of the models by the automatic selection.

```{r auto arima}
arima2 <- forecast::auto.arima(diff.train$dCPI, 
                               seasonal = F, 
                               ic = "aic", 
                               stepwise = F, 
                               approximation = F,
                               trace = F,
                               method = "ML")

summary(arima2)
```

We can see that the model automatically selected using the lowest AIC is the different from the one I had manually coded into the **`Arima`** function. The `arima2` model had a lower AIC and had a slightly higher log-likelihood than the `arima1` model. I plotted the actual CPI values and the fitted values based on the two ARIMA models to visualize how well the model fits.

```{r plot arima, fig.align='center', echo=FALSE}
# indicated xlim to zoom into the chart to have a better view of the patterns
plot(ts(diff.train$dCPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dCPI", main = "Actual vs Fitted CPI at First Difference Using ARIMA",
     xlim = c(1990, 2019))

lines(ts(fitted(arima1), start = c(1978, 2), frequency = 4), col = "red", type = "l", lwd = 3)

lines(ts(fitted(arima2), start = c(1978, 2), frequency = 4), col = "gray", type = "l", lwd = 3)

abline(h = arima2$coef[4], col = "black", lwd = 2)

legend(x = "topleft", legend = c("Actual dCPI", "arima1", "arima2", "Mean from arima2"),
       col = c("darkblue", "red", "gray", "black"), lwd = 1.5)
```

It seems that the `arima1` and `arima2` models approximately captures the pattern (with slight differences), although it does not seem to capture the magnitude of the movements in the CPI that well. ARIMA models can give us a benchmark to compare other types of time series models, either through in-sample prediction or out-of-sample forecast.

### 7.2 Autoregressive Distributed Lag Models

An ARDL model is similar to an ARMA model, except it used the lags of the dependent variables and lags of other explanatory variables to predict $y_t$. ARDL can be used on time series with combinations of I(0) and I(1).

The simplest ARDL model is one with an explanatory ($x$) and a dependent variable ($y$) and the notation for this is ARDL(p, q). Unlike the ARIMA models, an ARDL model allows us to capture the dynamic effects from $x$ to $y$. We can write the model as such:

$$
y_t = \alpha + \sum_{i=1}^p \alpha_i y_{t-i} + \sum_{j=0}^q \beta_i x_{t-i} + \epsilon_t
$$

In our case, we have more than 1 explanatory variables but the same concept applies. We can use the **`auto_ardl`** function in the **`ARDL`** package to automatically select an ARDL model that has the lowest AIC based on a maximum number of lags for the search.

```{r ardl1}
# max_order = 4 to indicate maximum lag in the search for all variables is 4
# possible to state a vector of length equal to no. of variables in max_order
# grid = T to to prevent stepwise search of models

ardl_lag <- ARDL::auto_ardl(formula = dCPI ~ dDSPI + dCLI,
                            data = as.zoo(diff.train),
                            max_order = 4, grid = T,
                            selection = "AIC")

# Obtain the best lag order, arranged by how variables were entered in the formula argument
ardl_lag$best_order

# Save the coefficients of the model selected by auto_ardl
ardl <- ardl_lag$best_model

summary(ardl)
```

Unlike the ARIMA output earlier, the ARDL output does not state the log-likelihood or the AIC values. This can be found using the **`logLik`** and **`AIC`** functions in base R.

```{r loglik and aic}
logLik(ardl)

AIC(ardl)
```

The log-likelihood is much higher and AIC much lower than the `arima2` model estimated in Section 9.1, which should indicate a better fit.

```{r plot ardl, fig.align='center', echo=FALSE}
plot.zoo(diff.train$dCPI,
         col = "darkblue", type = "l", lwd = 3,
         ylab = "dCPI", xlab = "Time",
         main = "Actual vs Fitted CPI at First Difference Using ARDL",
         xlim = c(1990, 2019))

lines(fitted(ardl), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCPI", "ardl"),
       col = c("darkblue", "red"), lwd = 1.5)
```

We can see a significant improvement in the fit of the `ardl1` model as compared to the `arima2` model in Section 9.1.

### 7.3 Vector Autoregressive Model

A VAR model allows us to model the influence of two or more time series on one another, meaning that these variables are endogenous. In VAR models, the variables (e.g. $x$ and $y$) are simultaneously determined by the lags of these variables. A VAR(p) model of two variables can be written as:

$$ 
y_t = beta_{10} + beta_{11} y_{t-1} + \dotsc + beta_{1p} y_{t-p} + gamma_{11} x_{t-1} + \dotsc + gamma_{1p} x_{t-p} + u_{1t} \\

x_t = beta_{20} + beta_{21} y_{t-1} + \dotsc + beta_{2p} y_{t-p} + gamma_{21} x_{t-1} + \dotsc + gamma_{2p} x_{t-p} + u_{2t} 
$$

We can see that with more lags and more variables included into the VAR system, there would be more unknown parameters and lesser degrees of freedom, which can affect estimation and statistical tests. However, if too few lags were included, we may encounter the problem of autocorrelated errors.

To build a VAR model, we first need to determine the optimal number of lags which can be done by using the **`VARselect`** function in the **`vars`** package.

```{r var lag}
var_lag <- vars::VARselect(y = diff.train,
                           lag.max = 4,
                           type = "const")

var_lag
```

Based on AIC, I would choose to use 2 lag for the VAR model, i.e. VAR(2) model. We could use the SC (or BIC) selected lags for a parsimonious model. The function **`VAR`** in the **`vars`** package allows us to estimate this model.

```{r var}
var <- vars::VAR(y = diff.train,
                 p = 2,
                 type = "const")

stargazer(var$varresult, 
          type = "text", 
          title = "VAR Estimation Result for dCPI, dDSPI, dCLI", 
          digits = 3, 
          column.labels = c("dCPI", "dDSPI", "dCLI"),
          dep.var.labels.include = F)
```

The output shows the three equations, one for each variable, with 2 lags of each variable. Therefore, the model gets really big as more variables and lags are added, which can become a problem. We can write it down as:

$$
\begin{aligned}

\Delta CPI_t &= 0.120 + 0.268\Delta CPI_{t-1} + 0.261\Delta CPI_{t-2} + 0.041\Delta DSPI_{t-1} - 0.004\Delta DSPI_{t-2} + 0.039\Delta CLI_{t-1} + 0.032\Delta CLI_{t-2} \\

\Delta DSPI_t &= -0.103 + 0.342\Delta DSPI_{t-1} - 0.276\Delta DSPI_{t-2} - 0.393\Delta CPI_{t-1} + 0.385\Delta CPI_{t-2} - 0.079\Delta CLI_{t-1} + 0.358\Delta CLI_{t-2} \\

\Delta CLI_t &= 0.484 + 0.346\Delta CLI_{t-1} - 0.061\Delta CLI_{t-2} - 0.039\Delta DSPI_{t-1} - 0.086\Delta DSPI_{t-2} - 0.051\Delta CPI_{t-1} - 0.381\Delta CPI_{t-2}

\end{aligned}
$$

```{r plot var dcpi, fig.align='center', echo=FALSE}
plot(ts(diff.train$dCPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dCPI", xlab = "Time",
     main = "Actual vs Fitted CPI at First Difference Using VAR")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(var$varresult$dCPI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCPI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

An advantage of models like VAR is that we can also plot the predicted values of other variables that are in the model.

```{r plot var ddspi, fig.align='center', echo=FALSE}
plot(ts(diff.train$dDSPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dDSPI", xlab = "Time",
     main = "Actual vs Fitted DSPI at First Difference Using VAR")

lines(ts(fitted(var$varresult$dDSPI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dDSPI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot var dcli, fig.align='center', echo=FALSE}
plot(ts(diff.train$dCLI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dCLI", xlab = "Time",
     main = "Actual vs Fitted CLI at First Difference Using VAR")

lines(ts(fitted(var$varresult$dCLI), start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCLI", "var"),
       col = c("darkblue", "red"), lwd = 1.5)
```

## 8 Granger Causality Test

Using the Granger Causality Test, we can statistically determine if a series can be used predict values of another series better than solely using its past values. Despite the name, it should not be used to determine true cause-and-effect relationships between variables. It can be a useful test to determine if variables should be added to a time series model to improve forecasting accuracy.

In simple terms, the Granger Causality Test checks if the lags of variable $x$ can be used to improve the forecast of variable 2 than solely basing on the lags of variable $y$. What the test does is to apply a Likelihood Ratio Test or a F-Test on the two models below. The null hypothesis is that $x$ does not granger-cause $y$, against the alternative that $x$ granger-causes $y$.

$$
\begin{aligned}
y_t &= \theta_0 + \theta_1 y_{t-1} + \gamma_1 x_{t-1} + e_t \\
y_t &= \theta_0 + \theta_1 y_{t-1} + e_t
\end{aligned}
$$

With two variables, we can test if $x$ granger-causes $y$, $y$ granger-causes $x$ or if there is bi-directional granger causality between $x$ and $y$. The set up would start to look like a VAR model, and there is indeed a package called **`bruceR`** that uses a VAR output to perform this test using the function **`granger_test`** for bivariate models and **`granger_causality`** for multivariate models.

```{r gc test}
granger_causality(varmodel = var)
```

The output provides both F-test and Likelihood Ratio Test values. Given the significance level of 5%, `dDSPI` and `dCLI` granger-cause `dCPI` and `dDSPI` granger-causes `dCLI`. None of the variables granger-cause `dDSPI` and we did not find any bi-directional causality. It may be that the wrong number of lags was chosen or simply that lags of other variables does not help in predicting other variables. In such cases, the forecasting power of this model may be affected since these variables are inter-dependent on one another.

## 9 Johansen Test for Cointegration

Since we have I(1) variables, we can model the variables at levels if they are found to have a cointegrating relationship. When variables are cointegrated, they appear to have the same long-run patterns and the difference between these two variables are stationary. In such cases, we could estimate a Error Correction Model (ECM) or a Vector Error Correction Model (VECM), which allows us to model long-run relationships between variables. If these I(1) variables are not cointegrated, we can only estimate a short-run model using the VAR or ARDL models.

To test for cointegration of multivariate time series, I have used the Johansen Test using the **`ca.jo`** function in the **`urca`** package. One of the arguments required is to specify the lag order of the level series in the VAR model. This can be determined using the **`VARselect`** function in the **`vars`** package.

```{r lag for jo test}
# Use the data at levels, not at first difference
lagselect <- vars::VARselect(train, lag.max = 4, type = "const")

lagselect$selection
```

To be constant throughout the project, I would use the AIC to select the number of lags. The `lagselect` output indicated we should use 3 lags for the Johansen Test.

```{r jo test trace}
# Indicate type = "trace" for trace test, "eigen" for eigenvalue test

# Indicate ecdet = "none" assuming no intercept in the cointegration process, indicate "const" or "trend" to add constant or trend into the equation
# It is common to indicate no deterministic terms in the error correction term unless there are reasons to believe otherwise

# K is the number of lags from the lag selection using VARselect

jotest <- urca::ca.jo(x = train, 
                      type = "trace", 
                      ecdet = "none", 
                      K = 3)

summary(jotest)
```

The test results are read starting from:

1.  r = 0: value under test column is more than value under 5pct column (statistically significant) and we have at least one cointegrating relationship.

2.  r <= 1: value under test column is less than value under 5pct column (statistically insignificant) and we have at most one cointegrating relationship.

Since we have found evidence of cointegration through the Johansen Test, we can estimate a ECM or VECM model.

### 9.1 Error Correction Model

Given the cointegration between variables, we can model the long-run equilibrium variable $y^*$ using the equilibrium of $x^*$ at levels. To model the short-run model, we need to remember that the variables are I(1), so we need to use a first-differenced equation, for example $\Delta y_t = \gamma_0 + \gamma_1 \Delta x_t + \epsilon_t$. But since there is a long-run association between $y$ and $x$, we could include some components into the short-run model so that it takes into account this long-run association. What we can add into the short-run model is the error correction term (ECT), which is the one-period ago residual from the long-run model. The following are the steps to modelling an ECM:

1. Regress $y^*$ on $x^*$ (and their lags) and obtain the residuals $v_t$

2. Regress $\Delta y_t$ on $\Delta x_t$ and the lag of the residual in Step 1, $v_{t-1}$

If there is indeed cointegration, the coefficient of $v_{t-1}$ should be between -1 and 0. This is because, taking the long-run pattern into account, if $y_{t-1}$ was above/below $y^*$, then we should expect $y_t$ to decrease/increase, showing an adjustment to the equilibrium. 

Let us first estimate a model in levels as per step one using **`auto_ardl`**

```{r ardl_lr}
ardl_lr_lag <- ARDL::auto_ardl(formula = CPI ~ DSPI + CLI,
                               data = as.zoo(train),
                               max_order = 4,
                               selection = "AIC",
                               grid = T)

ardl_lr <- ardl_lr_lag$best_model

summary(ardl_lr)
```

Instead of extracting the residuals, we can use the **`uecm`** and **`recm`** functions to get the unrestricted and restricted form of the ECM. The first model will show all the coefficients with the long-run and short-run variables, while the second will only show the short-run variables with the ECT.

```{r uecm}
un_ecm <- ARDL::uecm(ardl_lr)

summary(un_ecm)
```

`L(CPI, 1)` is the lag of our dependent variable and its coefficient is actually the ECT, which tells us how `CPI` would react given a shock to `L(CPI, 1)`. `L(DSPI, 1)` and `L(CLI, 1)` is the long-run coefficient (after some conversion) and the differenced variables (those starting with `d...`) are the short-run coefficients.

```{r recm}
# Indicated case = 3 to include constant in the model
r_ecm <- ARDL::recm(un_ecm, case = 3)

summary(r_ecm)
```

We can see that the `r_ecm` output is the same as the `un_ecm` output, less the long-run variables. And as expected, the ECT is negative and is between -1 and 0 (and statistically significant).

To obtain the long-run multiplier, we can use the **`multiplier`** function.

```{r lr multiplier}
stargazer(multipliers(un_ecm), # Can also be used on ardl_lr
          type = "text", 
          title = "Long Run Multipliers of var Model",
          summary = F)
```

The equation of the error correction model is:

$$
\begin{aligned}

\Delta CPI_t = &-0.119 + 0.196\Delta CPI_{t-1} + 0.126\Delta CPI_{t-2} + 0.036\Delta DSPI_t \\
& + 0.018\Delta DSPI_{t-1} - 0.031\Delta CLI_{t} + 0.039\Delta CLI_{t-1} - 0.030ECT_{t-1}


\end{aligned}
$$

```{r plot ardl ecm, fig.align='center', echo=FALSE}
plot.zoo(diff.train$dCPI, col = "darkblue", type = "l", lwd = 3,
         ylab = "dCPI", xlab = "Time",
         main = "Actual vs Fitted CPI at First Difference Using ARDL-ECM")

lines(fitted(r_ecm), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCPI", "ardl-ecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

### 9.2 Vector Error Correction Model

The VECM is simply a VAR model with error correction terms. What has been explained in Section 7.3 Vector Autoregressive Models and Section 9.1 Error Correction Model should be sufficient to give a glimpse of what a VECM is about. 

We can build a VECM using the **`urca`** package, using the functions **`ca.jo`**, **`cajools`** and **`cajorls`**. Although we had seen earlier in the Johansen Test that we used **`ca.jo`** to test the number of cointegrating relationships, it can also provide the VECM using the other functions mentioned.

```{r vecm}
# K = 3 was determined in Section 9 in the Johansen Test
# Add in spec = "transitory" to obtain the VECM formula

get_vecm <- ca.jo(x = train, 
                  type = "trace", 
                  ecdet = "none", 
                  K = 3,
                  spec = "transitory")


# Get estimated VAR parameters
# r represents number of cointegrations

vec_ecm <- cajorls(get_vecm, r = 1)

kable(tidy(summary(vec_ecm$rlm)[[1]]), format = "pipe",
      caption = "VECM Estimation Output for dCPI",
      digits = 4)

kable(tidy(summary(vec_ecm$rlm)[[2]]), format = "pipe",
      caption = "VECM Estimation Output for dDSPI",
      digits = 4)

kable(tidy(summary(vec_ecm$rlm)[[3]]), format = "pipe",
      caption = "VECM Estimation Output for dCLI",
      digits = 4)
```

The output shows the coefficients under the `estimate` column of each variable under the `term` column. The 3 equations in the VECM are:

$$
\begin{aligned}

\Delta CPI_t &= 0.1526 + 0.2691\Delta CPI_{t-1} + 0.2616\Delta CPI_{t-2} + 0.0406 \Delta DSPI_{t-1} -0.003\Delta DSPI_{t-2} \\
&~~~~
+ 0.0391\Delta CLI_{t-1} + 0.0314\Delta CLI_{t-2} - 0.0005 ECT_{t-1} \\

\Delta DSPI_t &= 15.5003 + 0.1272\Delta CPI_{t-1} + 0.8377\Delta CPI_{t-2} + 0.3030\Delta DSPI_{t-1} -0.2986\Delta DSPI_{t-2} \\
&~~~~
-0.1062\Delta CLI_{t-1} + 0.2283\Delta CLI_{t-2} -0.2222 ECT_{t-1} \\

\Delta CLI_t &= 1.1357 -0.0291\Delta CPI_{t-1} -0.3617\Delta CPI_{t-2} -0.0405\Delta DSPI_{t-1} -0.0865\Delta DSPI_{t-2} \\
&~~~~
+0.3452\Delta CLI_{t-1} -0.0660\Delta CLI_{t-2} -0.0093 ECT_{t-1}

\end{aligned}
$$

```{r plot vecm cpi, fig.align='center', echo=FALSE}
plot(ts(diff.train$dCPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dCPI", xlab = "Time",
     main = "Actual vs Fitted CPI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"CPI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCPI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot vecm dspi, fig.align='center', echo=FALSE}
plot(ts(diff.train$dDSPI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dDSPI", xlab = "Time",
     main = "Actual vs Fitted DSPI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"DSPI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dDSPI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

```{r plot vecm cli, fig.align='center', echo=FALSE}
plot(ts(diff.train$dCLI, start = c(1978, 2), frequency = 4),
     col = "darkblue", type = "l", lwd = 3,
     ylab = "dCLI", xlab = "Time",
     main = "Actual vs Fitted CLI at First Difference Using VECM")

# Start period is 1978Q4 since we used 2 lags, resulting in loss of first 2 observations
lines(ts(fitted(vec_ecm$rlm)[,"CLI.d"], start = c(1978, 4), frequency = 4), col = "red", type = "l", lwd = 3)

legend(x = "bottomleft", legend = c("Actual dCLI", "vecm"),
       col = c("darkblue", "red"), lwd = 1.5)
```

We can also convert the VECM in differences to a VAR in levels using the **`vec2var`** function, which is particularly useful when we are forecasting since it gives us the output in levels.

```{r vec2var}
var_ecm <- vec2var(get_vecm, r = 2)

var_ecm
```

## 10 Post-Estimation Tests

Two common problems encountered in time series analysis are serial correlation of errors and heteroskedastic errors. These can affect our analysis as estimators are no longer efficient and the usual test statistics become unreliable, which can be important if inference is the main purpose. The Breusch-Godfrey Test can be used to test for serial correlation, while the Breusch-Pagan Test can be used to test for heteroskedasticity. However, there is no single package that could accommodate different models for these tests, so we will have to use different functions from different packages for the models that are accepted.

However, using Newey-West standard errors to obtain the corrected test statistics regardless of whether serial correlation and/or heteroskedasticity is present seems to be an acceptable method, especially when we have large sample sizes.

### 10.1 ARDL Model

We can use the **`bgtest`** and **`bptest`** from the **`lmtest`** package.

```{r bg ardl}
# Test with up to 4 lags of the residuals

lmtest::bgtest(ardl, order = 4)
```

```{r bp ardl}
lmtest::bptest(ardl, studentize = T)
```

There is serial correlation and heteroskedasticity in the ARDL residuals, and we should use the Newey-West (Heteroskedasticity and Autocorrelation Corrected) standard errors to obtain the correct test statistics for inference.

### 10.2 VAR Model

The functions that can be applied to VAR models are **`serial.test`** and the **`arch.test`** from the **`vars`** package. The **`arch.test`** performs the ARCH test to detect if there is changing conditional variance in a time series, unlike the Breusch-Pagan test that detects for constant variance.

```{r bg var}
vars::serial.test(var, lags.bg = 4, type = "BG")
```

```{r arch var}
vars::arch.test(var, lags.single = 4, lags.multi = 4, multivariate.only = F)
```

From the tests, there are was no serial correlation detected at up to 4 lags of the error term, and only `dCPI` and the overall VAR models has ARCH effects. 

### 10.3 VECM

```{r bg vecm}
vars::serial.test(var_ecm, lags.bg = 4, type = "BG")
```

```{r arch vecm}
vars::arch.test(var_ecm, lags.single = 4, lags.multi = 4, multivariate.only = F)
```

Similar to the tests for the VAR model, there is no serial correlation detected at up to 4 lags of the error terms and only the `CPI` single equation and the multivariate model has ARCH effects. 

## 11 Forecasting and Evaluation

For the forecast and evaluation, I would compare the data at first difference in the `diff.test` dataset against the 8 period ahead forecasted values. This would mean that the forecasted values are for the periods 2020 Q1 to 2021 Q4. I then plotted the actual vs forecasted values at levels to see how well the different models fit. However, there are two points to keep in mind. 

Firstly, the forecasted values will be in first-difference. Conversion to levels will be needed, which can be obtained simply by adding the cumulative forecasted values to the last observation used in the `diff.train` dataset.

Secondly, models such as ARIMA and VAR uses endogenous variable but ARDL models contains exogenous variables. This means that we would need data on the exogenous variables in the ARDL models for the forecasting to work. This can be done through the use of ARIMA models to predict exogenous variables before inputting them into the ARDL forecast. However, for simplicity, I would use the data in the `diff.test` set to compare the performance of the ARDL and ARDL-EC models while ARIMA and VAR/VECM would be compared to one another.

For the ARIMA models, we can generate forecast values using the **`forecast`** function in the **`forecast`** package. For ARDL, we would need to use the **`dLagM`** package and for ARCL-ECM we need to use the **`ecm`** package as they have their own forecast functions. For VAR and VECM models, we need to use the **`predict`** function from the base R package. 

### 11.1 Forecast Performance of ARIMA Models

```{r arima1 h8}
arima1_h8 <- forecast(object = arima1, h = 8, level = 95)

stargazer(as.data.frame(arima1_h8), 
          type = "text",
          title = "Forecasted dCPI 2020Q1 to 2021Q4 Using arima1 Model", 
          summary = F)

stargazer(accuracy(object = arima1_h8, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of arima1 Model for 8-Steps Ahead Forecasting")
```

R simply refers to the row number of the observations and does not correct the dates assigned to each observation after the use of lags in the models as can be seen in the table of the forecasted `dCPI` values. It would be important to take note of this point when plotting the forecasted values.

The accuracy measures Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute Scaled Error (MASE) can be compared across models and lower values would indicate better out-of-sample forecast. The Mean Absolute Percentage Error (MAPE) can also be used, but may not be useful in cases where we might have zeroes in data. For the out-of-sample forecast, we are interested in the accuracy measures of the `Test set` row.

```{r plot f_arima1, fig.align='center', echo=FALSE}
fcpi_arima1 <- ts(cbind(fcpi = as.vector(last(train$CPI)) + cumsum(arima1_h8$mean),
                     fcpi_lower = as.vector(last(train$CPI)) + cumsum(arima1_h8$lower),
                     fcpi_upper = as.vector(last(train$CPI)) + cumsum(arima1_h8$upper)),
                  start = c(2020, 1),
                  frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_arima1), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model arima1")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

For model `arima2`, I suppressed the code to reduce the length of the document since it is similar to what I did for model `arima1`.

```{r arima2 h8, echo=FALSE}
arima2_h8 <- forecast(object = arima2, h = 8, level = 95)

stargazer(as.data.frame(arima2_h8), 
          type = "text",
          title = "Forecasted dCPI 2020Q1 to 2021Q4 Using arima2 Model", 
          summary = F)

stargazer(accuracy(object = arima2_h8, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of arima2 Model for 8-Steps Ahead Forecasting")
```

```{r plot f_arima2, fig.align='center', echo=FALSE}
fcpi_arima2 <- ts(cbind(fcpi = as.vector(last(train$CPI)) + cumsum(arima2_h8$mean),
                     fcpi_lower = as.vector(last(train$CPI)) + cumsum(arima2_h8$lower),
                     fcpi_upper = as.vector(last(train$CPI)) + cumsum(arima2_h8$upper)),
                  start = c(2020, 1),
                  frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_arima2), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model arima2")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

There seemed to be negligible differences between the models `arima1` and `arima2`, so it might be better to go with the simpler `arima2` when using ARIMA models for forecasting Singapore CPI.

### 11.2 Forecast Performance of ARDL and ARDL-EC Models

To forecast the ARDL and ARDL-EC models, we need values for the exogenous variables. However, as there are lags in the model as well, **`forecast`** and **`predict`** functions do not work well with the underlying **`dynlm`** objects of these models. To resolve this, we have to use the **`dLagM`** package function **`ardlDlm`** to fit the ARDL model. The **`dLagM`** package also contains its own **`forecast`** function.

```{r ardl h8}
ardl.new <- ardlDlm(formula = dCPI ~ dDSPI + dCLI, # Indicate variables for the ARDL model
                    data = data.frame(diff.train), 
                    p = 2, q = 4, # Include 2 lags for exogenous variables, 4 lags for dependent variable
                    remove = list(p = list(dDSPI = c(2)))) # Remove second lag for dDSPI so that model is same as auto_ardl

stargazer(ardl.new$model, type = "text",
          title = "ARDL Regression Using dLagM Package", 
          dep.var.labels.include = F, 
          column.labels = "CPI.t")

x.new <- rbind(as.vector(diff.test["2020/2021", 2]), as.vector(diff.test["2020/2021", 3])) # function only accepts new data in matrix class

ardl_h8 <- dLagM::forecast(model = ardl.new, x = x.new, h = 8, interval = T, level = 0.95)

stargazer(ardl_h8$forecasts, 
          type = "text",
          title = "Forecasted dCPI 2020Q1 to 2021Q4 Using ardl Model", 
          summary = F)

# To use the accuracy function in the forecast package, we need to trick it into thinking it is a object of class "forecast"

ardl_h8adj <- structure(list(level = 95,
                             mean = ardl_h8$forecasts$Forecast, 
                             lower = ardl_h8$forecasts$`95% LB`, 
                             upper = ardl_h8$forecasts$`95% UB`, 
                             x = diff.train[, 1], 
                             fitted = c(rep(NA, 4), ardl.new$model$fitted.values),
                             residuals = c(rep(NA, 4), ardl.new$model$residuals)), 
                        class = "forecast")

stargazer(accuracy(object = ardl_h8adj, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of ardl Model for 8-Steps Ahead Forecasting")
```

```{r plot f_ardl, fig.align='center', echo=FALSE}
fcpi_ardl <- ts(cbind(fcpi = as.vector(last(train$CPI)) + cumsum(ardl_h8adj$mean),
                      fcpi_lower = as.vector(last(train$CPI)) + cumsum(ardl_h8adj$lower),
                      fcpi_upper = as.vector(last(train$CPI)) + cumsum(ardl_h8adj$upper)),
                start = c(2020, 1),
                frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_ardl), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model ardl")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

For the ARDL-ECM, since we have found cointegration we could simply obtain the forecast in levels since there is a long-run model `ardl_lr`. Of course, there will still be a need to model and forecast it using the **`dLagM`** package for it to work.

```{r ardl ecm h8}
ardlecm.new <- dLagM::ardlDlm(formula = CPI ~ DSPI + CLI, data = data.frame(train), p = 2, q = 3)

stargazer(ardlecm.new$model, 
          type = "text",
          title = "ECM Regression Using dLagM Package", 
          dep.var.labels.include = F, 
          column.labels = "CPI.t")

newdata <- rbind(as.vector(test["2020/2021", 2]), as.vector(test["2020/2021", 3]))

ecm_h8 <- dLagM::forecast(model = ardlecm.new, x = newdata, h = 8, interval = T, level = 0.95)

stargazer(ecm_h8$forecasts, 
          type = "text",
          title = "Forecasted dCPI 2020Q1 to 2021Q4 Using ecm Model", 
          summary = F)

# Since forecast values are CPI at level, we cannot directly compare to the accuracy measures of other models since they have different scales
# We can get the first difference CPI by taking the difference of the forecasted values

dcpi_ecm <- data.frame(fcst = na.omit(diff(append(ecm_h8$forecasts$Forecast, as.vector(last(train$CPI)), 0))),
                       lowerb = na.omit(diff(append(ecm_h8$forecasts$`95% LB`, as.vector(last(train$CPI)), 0))),
                       upperb = na.omit(diff(append(ecm_h8$forecasts$`95% UB`, as.vector(last(train$CPI)), 0))))

# Creating structure of class "forecast" that can be used with the accuracy function

ecm_h8adj <- structure(list(level = 95,
                            mean = dcpi_ecm$fcst,
                            lower = dcpi_ecm$lowerb,
                            upper = dcpi_ecm$upperb,
                            x = diff.train[, 1],
                            fitted = c(rep(NA, 2), r_ecm$fitted.values),
                            residuals = c(rep(NA, 2), r_ecm$residuals)),
                       class = "forecast")

stargazer(accuracy(object = ecm_h8adj, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of ecm Model for 8-Steps Ahead Forecasting")
```

```{r plot ecm, fig.align='center', echo=FALSE}
fcpi_ecm <- ts(cbind(fcpi = ecm_h8$forecasts$Forecast,
                     fcpi_lower = ecm_h8$forecasts$`95% LB`,
                     fcpi_upper = ecm_h8$forecasts$`95% UB`),
               start = c(2020, 1),
               frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_ecm), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model ardl-ecm")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

### 11.3 Forecast Performance of VAR and VEC Models

Forecasting VAR and VEC models is much simpler that for ARDL and ARDL-EC models in R. It simply requires the **`predict`** function in base R. However, we still need to create a list object of class `forecast` that works with the **`accuracy`** function.

```{r var h8}
var_h8 <- predict(object = var, n.ahead = 8, ci = 0.95)

stargazer(var_h8$fcst, 
          type = "text", 
          title = c("Forecasted dCPI from 1Q20 to 4Q21", "Forecasted dDSPI from 1Q20 to 4Q21", "Forecasted dCLI from 1Q20 to 4Q21"))

# Creating structure of class "forecast" that can be used with the accuracy function

var_acc_list <- list()

for (i in 1:3) {
  fc <- structure(list(level = 95,
                       mean = var_h8$fcst[[i]][,"fcst"],
                       lower = var_h8$fcst[[i]][,"lower"],
                       upper = var_h8$fcst[[i]][,"upper"],
                       x = diff.train[,i],
                       fitted = c(NA, NA, fitted(var)[,i]),
                       residuals = c(NA, NA, resid(var)[,i])),
                  class = "forecast")
  
  name <- paste(names(var_h8$fcst[i]), "_acc", sep = "") 
  
  var_acc_list[[name]] <- fc
}

stargazer(accuracy(object = var_acc_list$dCPI_acc, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of var Model for 8-Steps Ahead Forecasting for dCPI")

stargazer(accuracy(object = var_acc_list$dDSPI_acc, x = diff.test["2020/2021"]$dDSPI), 
          type = "text", 
          title = "Accuracy Measures of var Model for 8-Steps Ahead Forecasting for dDSPI")

stargazer(accuracy(object = var_acc_list$dCLI_acc, x = diff.test["2020/2021"]$dCLI), 
          type = "text", 
          title = "Accuracy Measures of var Model for 8-Steps Ahead Forecasting for dCLI")
```

```{r plot f_var, fig.align='center', echo=FALSE}
fcpi_var <- ts(cbind(fcpi = as.vector(last(train$CPI)) + cumsum(var_h8$fcst[["dCPI"]][,"fcst"]),
                     fcpi_lower = as.vector(last(train$CPI)) + cumsum(var_h8$fcst[["dCPI"]][,"lower"]),
                     fcpi_upper = as.vector(last(train$CPI)) + cumsum(var_h8$fcst[["dCPI"]][,"upper"])),
               start = c(2020, 1),
               frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_var), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model var")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

For the VECM, R does not have a function that allows us to forecast the VECM in differences. We have to use the VAR in levels that was converted from the model `vec_ecm` using the **`vec2var`** function.

```{r var ecm h8}
vecm_h8 <- predict(var_ecm, n.ahead = 8, ci = 0.95)

stargazer(vecm_h8$fcst, 
          type = "text", 
          title = c("Forecasted dCPI from 1Q20 to 4Q21", "Forecasted dDSPI from 1Q20 to 4Q21", "Forecasted dCLI from 1Q20 to 4Q21"))

# Just as in the ARDL-ECM case, the forecasted values are in levels and we cannot directly compare to the other models.
# Need to take the difference of the forecasted values

dforecast_vecm <- list()

for (i in 1:3) {
  dforecast <- data.frame(fcst = na.omit(diff(append(vecm_h8$fcst[[i]][,"fcst"], as.vector(last(train$CPI)), 0))),
                          lowerb = na.omit(diff(append(vecm_h8$fcst[[i]][,"lower"], as.vector(last(train$CPI)), 0))),
                          upperb = na.omit(diff(append(vecm_h8$fcst[[i]][,"upper"], as.vector(last(train$CPI)), 0))))
  
  name <- paste("diff_", names(vecm_h8$fcst[i]), sep = "")
  
  dforecast_vecm[[name]] <- dforecast
}

# Create "forecast" structure to be used with the accuracy function

vecm_acc_list <- list()

for (i in 1:3) {
  fc <- structure(list(level = 95,
                       mean = dforecast_vecm[[i]][,"fcst"],
                       lower = dforecast_vecm[[i]][,"lowerb"],
                       upper = dforecast_vecm[[i]][,"upperb"],
                       x = diff.train[,i],
                       fitted = c(rep(NA, 2), fitted(vec_ecm[["rlm"]])[,i]),
                       residuals = c(rep(NA, 2), resid(vec_ecm[["rlm"]])[,i])),
                  class = "forecast")
  
  name <- paste(names(dforecast_vecm[i]), "_acc", sep = "") 
  
  vecm_acc_list[[name]] <- fc
}

stargazer(accuracy(object = vecm_acc_list$diff_CPI_acc, x = diff.test["2020/2021"]$dCPI), 
          type = "text", 
          title = "Accuracy Measures of vecm Model for 8-Steps Ahead Forecasting for dCPI")

stargazer(accuracy(object = vecm_acc_list$diff_DSPI_acc, x = diff.test["2020/2021"]$dDSPI), 
          type = "text", 
          title = "Accuracy Measures of vecm Model for 8-Steps Ahead Forecasting for dDSPI")

stargazer(accuracy(object = vecm_acc_list$diff_CLI_acc, x = diff.test["2020/2021"]$dCLI), 
          type = "text", 
          title = "Accuracy Measures of vecm Model for 8-Steps Ahead Forecasting for dCLI")
```

```{r plot f_vecm, fig.align='center', echo=FALSE}
fcpi_vecm <- ts(cbind(fcpi = vecm_h8$fcst[["CPI"]][,"fcst"],
                      fcpi_lower = vecm_h8$fcst[["CPI"]][,"lower"],
                      fcpi_upper = vecm_h8$fcst[["CPI"]][,"upper"]),
                start = c(2020, 1),
                frequency = 4)

plot.zoo(cbind(as.zoo(fcpi_vecm), test$CPI["2020/2021",], train$CPI["2016/2019"]), 
         plot.type = "single", 
         col = c("red", "gray", "gray", "blue", "black"), lwd = 3,
         ylab = "CPI", xlab = "Year/Quarter",
         main = "Actual and Forecasted CPI Using Model vecm")

legend(x = "topleft", 
       legend = c("Forecasted CPI", "Lower and Upper Bound", "Actual CPI 1Q20 to 4Q21", "Actual CPI 1Q16 to 4Q19"), 
       col = c("red", "gray", "blue", "black"), 
       lwd = 1.5)
```

## 12 Conclusion

In this project, I have detailed the 5 common time series models used in forecasting that I have learnt. Through this project, we can experience how using R for time series analysis feels like. It is not as simple as using EViews or Stata as the packages have their own quirks and functions can be repeated across packages but only serve models that are built by those packages.

The ARIMA models gives us a quick and easy forecasting method as we are just using the lags of CPI and its residuals, without the need of exogenous variables. However, whether in-sample or out-of-sample prediction, these models do not capture much of the magnitude of the movements in CPI although they are able to capture its patterns.

The ARDL model was able to use exogenous variables to provide a better fit to the data, both in-sample and out-of-sample. However, for out-of-sample prediction, I had used actual data of the exogenous variables, which cannot happen for real-world forecasting methods. The correct method would be to use another model to forecast the exogenous variables and use these forecasted values fit the out-of-sample prediction. This means that the accuracy of the forecast depends on both the CPI model and the models of other variables.

The VAR model can be used when all variables are endogenous and can be used to explain one another. By using VAR models, we solved the problem of ARDL models by allowing variables to be forecasted at the same time. However, despite the good in-sample fit, the out-of-sample fit is disappointing. This is likely due to the findings of the Granger Causality Test, where DSPI and CLI can be used to improve the prediction of CPI but other variables have lack of granger causality. This would be a model misspecification and would lead to poor forecasting results.

The Johansen Test was used to determine if cointegration exists between the variables and we found that there is a cointegrating relationship. This was the reason for using the ECM and VECM. The ECM had much better out-of-sample forecasts than the VECM, although this could be attributed to using actual data for the exogenous variables. However, we can see that the VECM was unable to capture the rising trend of the CPI in levels through the forecast, which again could be due to model misspecification as in the VAR model case.

For the case of forecasting Singapore CPI, ARIMA models seem to have the best forecasting ability among the models given its simplicity. It would be interesting to find out if using ARDL with forecasted exogenous variables could still provide a better forecast accuracy than the ARIMA models in the future. As for the VAR and VECM models, there would be a need to re-specify the models or simply fit the models individually just as in the ARDL case. I had also ignored the effects of seasonality in this project, which I would discuss separately in the future as well.
