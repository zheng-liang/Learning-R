---
title: "Effect of Risk Measures on Portfolio Composition and Performance"
author: "zhengliang"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::knit_hooks$set(purl = knitr::hook_purl)
```

## 1 Introduction

The purpose of this project is to determine the effect of different risk measures on portfolio performance. This project uses the Variance/Standard Deviation, Semi-Variance/Semi-Deviation, Downside Deviation (DD), Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR) as the measures of risk for comparison.

The first part introduces the different risk measures using a single security. The second part shows how the different risk measures are used to optimize a portfolio with more than one security for a single-period. I first created a category of portfolios that minimizes the different risk measures, then created a category of optimal portfolios that minimizes the different risk measures for a given level of return. In each category of portfolios, I compared their performance and charted their cumulative returns.

The results in this project should not be taken as investment advice, and is not intended to be investment advice.

## 2 Packages Required

```{r load packages, message=FALSE, warning=FALSE}
library(dplyr)
library(doParallel) # For parallel computation in foreach loops
library(PerformanceAnalytics) # For portfolio performance and risk analysis
library(PortfolioAnalytics) # For portfolio optimization and analysis
library(quantmod) # For obtaining historical prices from Yahoo Finance
```

## 3 Understanding Risk Measures

In this section, the different risk measures are introduced, starting with Variance/Standard Deviation as it is the fundamental risk measure of the Mean-Variance Framework developed by Harry Markowitz. Subsequently, I described the Semi-Variance/Semi-Deviation and Downside Deviation that measures only the downside risk or the negative fluctuations, followed by VaR and CVaR which measures the tail risk. The **`PerformanceAnalytics`** package provides the necessary functions for the different risk measures.

I used the stock returns of Microsoft Corporation (MSFT) to illustrate the different risk measures, which can be obtained using the **`getSymbols`** function in **`quantmod`** package.

```{r msft price}
startdate <- "2010-01-01"
enddate <- "2022-06-01"

MSFT <- quantmod::getSymbols(Symbols = "MSFT", # Indicate a symbol that corresponds to stock in Yahoo Finance
                             src = "yahoo", # Indicate to search stock prices from Yahoo Finance
                             from = startdate, # Indicate a start date
                             to = enddate, # Indicate an end date
                             periodicity = "daily", # Indicate the periodicity of prices to retrieve, can also be "weekly" or "monthly"
                             auto.assign = F) # Indicate FALSE so that results are assigned to variable we indicate

head(MSFT, n = 4); tail(MSFT, n = 4)

colSums(is.na(MSFT)) # To check for NA values
```

The adjusted price would be used to calculate the daily return since it has been adjusted for dividend and splits.

```{r msft returns}
MSFT_returns <- PerformanceAnalytics::Return.calculate(prices = MSFT[,6], # Use the 6th column of MSFT (Adjusted Price)
                                                       method = "discrete" # Calculate the arithmetic/discrete returns, use "log" for log/continuous returns
                                                       )[-1,] # Remove first row since first price observation cannot be used to calculate return

head(MSFT_returns, 4)
```

### 3.1 Variance and Standard Deviation

The variance measures the sum of squared deviations from the expected return and this can be written as:

$$
\sigma^2 = \sum^N_{n=1} \frac{(R_n - E(R))^2}{N}
$$

The standard deviation is the square root of the variance or $\sqrt{\sigma^2_i}$. We can calculate the standard deviation of returns using the function **`StdDev`**.

```{r stddev msft}
MSFT_stddev <- PerformanceAnalytics::StdDev(R = MSFT_returns)

MSFT_stddev
```

The value of 0.016 means that 68% of the expected daily return would range between the mean return $\pm$ 0.016 (1 sd).

However, the variance and standard deviation as a measure of risk are typically countered by two arguments. Firstly, it assumes that returns are normally distributed, which is usually not satisfied when dealing with financial returns. Secondly, it penalizes downside and upside risks equally, but investors are usually more concerned with downside risks than upside risks. In optimizing portfolio composition, the Mean-Variance Framework limits not just the losses, but also the gains. Therefore, different measures of risk have been developed to capture the left side of the distribution instead.

```{r distribution of msft returns}
PerformanceAnalytics::chart.Histogram(MSFT_returns, 
                                      main = "Distribution of MSFT Daily Returns",
                                      methods = c("add.density", "add.normal"))

PerformanceAnalytics::skewness(MSFT_returns, method = "sample")

PerformanceAnalytics::kurtosis(MSFT_returns, method = "sample")
```

The daily return distribution of MSFT is slightly positively skewed, and has very high kurtosis (normal distribution has kurtosis of 3). Majority of the daily returns are concentrated around the mean as can be seen in the chart, but there are very long-tails, meaning that there can be extremely large daily losses or gains. Hence, the daily returns of MSFT are not normally distributed (can be confirmed with a formal test, such as Jarque-Bera or Shapiro-Wilks Test).

### 3.2 Semi-Variance and Semi-Deviation

The semi-variance and semi-deviation is similar to the variance and standard deviation, except that it only measures deviations below the expected return or the downside risk. The semi-deviation formula is written as:

$$
\sigma_{semi} = \sqrt{\sum_{n=1}^N \frac{\min(R_n - E(R), 0)^2}{N}} ~, \text{where N = total number of observations}
$$

We can calculate the semi-deviation of MSFT daily returns using the function **`SemiDeviation`**.

```{r semid msft}
MSFT_semidev <- PerformanceAnalytics::SemiDeviation(MSFT_returns)

MSFT_semidev
```

By using the semi-deviaion as a measure of risk, MSFT now has lower risk than if we had used the standard deviation (0.011 < 0.016). However, we are unable to use semi-deviation to determine the range of values that the daily returns would fall under a given probability, as we did using the standard deviation.

### 3.3 Downside Deviation

The downside deviation is similar to the semi-deviation, but it measures deviations below a target return (called the Minimum Acceptable Return or MAR). The formula is written as:

$$
DD = \sqrt{\sum_{n=1}^N \frac{\min(R_n - \text{MAR}, 0)^2}{N}} ~, \text{where N = total number of observations}
$$

Common values of MAR include the risk-free rate or zero, and if the mean of the returns is used, we would calculate the semi-deviation. Throughout this project, the MAR that I would use is 3%, which is approximately the yearly inflation rate.

```{r dd msft}
MSFT_downdev <- PerformanceAnalytics::DownsideDeviation(MSFT_returns, MAR = 0.03/252) # divide by 252 to change to daily periodicity

MSFT_downdev
```

Because the MAR is lesser than the expected MSFT daily return, we should obtain a smaller DD value than the semi-deviation. The DD might be a better measure of risk than the semi-deviation since the expected return may not be a good measure of the MAR.

### 3.4 Value-at-Risk

VaR measures the amount of loss that could occur over a specific time period, given a confidence level. For example, a 95% VaR of \$1 million with a time period of 1 month means that we are 95% confident that the loss would not exceed \$1 million. We can also rephrase it as we are 5% confident that the loss is greater than \$1 million over 1 month. The plot shows how VaR is indicated on a distribution of returns (chart has been zoomed in to allow better visualization):

```{r plot VaR, fig.align='center'}
PerformanceAnalytics::chart.Histogram(MSFT_returns, 
                                      main = "Distribution of MSFT Daily Returns with VaR",
                                      methods = c("add.risk"), # Indicate to show VaR and Modified VaR
                                      xlim = c(-0.05, 0.05)) # Zoom in chart
```

There are generally three basic measures of VaR, namely the Historical VaR (HVaR), Parametric VaR (PVaR) and Modified VaR. 

For 95% HVaR, we determine the value of actual return distribution at the 5% probability. As it uses the historical returns to calculate the VaR, HVaR does not make any assumptions about the distribution of returns.

```{r HVaR msft}
MSFT_hvar <- PerformanceAnalytics::VaR(MSFT_returns,
                                       p = 0.95, # confidence level of 95%
                                       method = "historical") # use historical VaR

MSFT_hvar
```

Based on the HVaR, we are 95% confident that the daily loss would not exceed 0.024 (or 2.4%). The statements "We are 95% confident that MSFT daily gain will be at least -0.024" and "We are 5% confident that MSFT daily loss would exceed 0.024" are equivalent.

For 95% PVaR, we also determine the value of the return distribution at 5% probability, but we assume that the returns are normally distributed. PVaR is also known as the variance-covariance VaR.

```{r PVaR msft}
MSFT_pvar <- PerformanceAnalytics::VaR(MSFT_returns,
                                       p = 0.95, 
                                       method = "gaussian") # gaussian (normal) distribution

MSFT_pvar
```

Based on the PVaR, we are 95% confident that the daily loss in MSFT would not exceed 0.025.

Modified VaR (also called Cornish-Fisher VaR) accounts for the skewness and kurtosis of the return distribution, which should be preferred when returns are not normally distributed.

```{r modVaR msft}
MSFT_modvar <- PerformanceAnalytics::VaR(MSFT_returns, 
                                         p = 0.95, 
                                         method = "modified") # use modified VaR

MSFT_modvar
```

Based on the Modified VaR, we are 95% confident that the daily loss in MSFT would not exceed 0.022.

While VaR allows us to determine the amount of loss that could occur within a time period at a given confidence interval, it does not actually quantify the loss that could occur beyond the VaR.

### 3.5 Conditional Value-at-Risk

CVaR, also known as the expected shortfall (ES) or expected tail loss (ETL) measures the loss occurring beyond the VaR. Similar to VaR, the calculation of CVaR can be based on the historical, parametric, or modified methods. In the **`PerformanceAnalytics`** package, the functions **`CVaR`**, **`ES`** and **`ETL`** are equivalent. For a 95% CVaR, we calculate the average of the 5% tail loss. 

```{r historical CVaR msft}
MSFT_histcvar <- PerformanceAnalytics::CVaR(MSFT_returns, 
                                            p = 0.95, 
                                            method = "historical")

MSFT_histcvar
```

Based on the historical method of CVaR, the average loss in the 5% tail of the return distribution is 0.036 or 3.6%.

```{r parametric CVaR msft}
MSFT_parcvar <- PerformanceAnalytics::CVaR(MSFT_returns,
                                           p = 0.95, 
                                           method = "gaussian")

MSFT_parcvar
```

Based on the parametric CVaR, the average loss in the 5% tail of the return distribution is 0.032. We can see that the loss is less than the historical CVaR although PVaR \< HVaR, which may be due to the false assumption of normality of the return distribution (not properly accounting for the tail).

```{r modified CVaR msft}
MSFT_modcvar <- PerformanceAnalytics::CVaR(MSFT_returns, 
                                           p = 0.95, 
                                           method = "modified")

MSFT_modcvar
```

Based on the modified CVaR, the average loss in the 5% tail of the return distribution is 0.031.

### 3.6 Summary of Risk Measures

In this section, we have seen the different variations of risk measures, with the standard deviation, semi-deviation and downside deviation measuring fluctuations of returns around or below a specified value and VaR and CVaR measuring the tail losses.

Here are the values of the risk measures calculated in this section, summarized into two categories:

```{r summary of risk measures}
c(Std_Dev = MSFT_stddev, Semi_Dev = MSFT_semidev, Downside_Dev = MSFT_downdev)

c(H_VaR = MSFT_hvar, P_VaR = MSFT_pvar, Mod_VaR = MSFT_modvar,
  H_CVaR = MSFT_histcvar, P_CVaR = MSFT_parcvar, Mod_CVaR = MSFT_modcvar)
```

For the VaR and CVaR calculations, it is assumed that historical values can determine future patterns of returns since we are using the actual historical data. There is another method that is widely used involving Monte Carlo simulations to simulate the returns for more predictive patterns of VaR and CVaR. However, I would not discuss this here as there are no existing packages or functions for Monte Carlo VaR and CVaR, and would require the coding of the MC simulation manually.

## 4 Retrieving Data For Portfolio

In this section, we start applying the different risk measures into the portfolio optimization problem. I have chosen to use index funds that represents stock indices of different major economies:

* US Large-Cap Equities: iShares Core S&P 500 ETF (IVV)
* US Small-Cap Equities: iShares Russell 2000 ETF (IWM)
* Europe Equities: Vanguard FTSE Europe ETF (VGK)
* Japan Equities: iShares MSCI Japan ETF (EWJ)
* Emerging Market Equities: Vanguard FTSE Emerging Markets ETF (VWO)

I have retrieved the historical price data of each ETF, keeping only the adjusted price column. I have used the same start and end date for data retrieval as Section 3.

```{r portfolio price data}
tickers <- c("IVV", "IWM", "VGK", "EWJ", "VWO")

price_data <- NULL

for (ticker in tickers) {
  price_data <- cbind(price_data,
                      quantmod::getSymbols(ticker, 
                                           src = "yahoo", 
                                           from = startdate, to = enddate, 
                                           periodicity = "daily", 
                                           auto.assign = F)[,6])
}

colnames(price_data) <- tickers
```

Let us take a look at the `price_data` object we have created to make sure that the data is correctly retrieved.

```{r head tail of price data}
head(price_data, n = 4); tail(price_data, n = 4)

nrow(price_data)

colSums(is.na(price_data))
```

We have a total of 3124 observations per security and there are no NA values in the columns. Now that we have ensured the price data is in time order and there are no missing values, we can calculate the daily returns of each security.

```{r individual security return}
returns <- na.omit(PerformanceAnalytics::Return.calculate(price_data, method = "discrete"))

head(returns)

nrow(returns)
```

With the `returns` data, we can proceed with optimizing the portfolios based on different risk measures. I created portfolios that minimizes the different risk measures in Section 5 and optimal portfolios that minimizes risk for a given level of return in Section 6.

## 5 Minimum Risk Portfolios

In this section, I would start by creating the minimum variance portfolio, followed by portfolios with minimum semi-variance, downside deviation, VaR and CVaR. The creation of these portfolios require the package **`PortfolioAnalytics`**. 

Before proceeding with the creation of portfolio objectives to minimize risk, I have created an initial portfolio specification with common constraints. It includes a sum of weight and individual asset weight constraints, which can be used throughout the different portfolio optimization problems.

```{r initial portfolio spec}
init_spec <- PortfolioAnalytics::portfolio.spec(assets = colnames(returns))

# Sum of weights constrained to 1 but require some "wiggle" room for random portfolio generation
init_spec <- add.constraint(portfolio = init_spec, 
                            type = "weight_sum", 
                            min_sum = 0.99, max_sum = 1.01)

# Weight of each asset is constrained to min of 0 and max of 40% of portfolio
init_spec <- add.constraint(portfolio = init_spec, 
                            type = "box", 
                            min = 0, max = 0.40)
```

While the `ROI` solver can be used with var/StdDev and ETL/ES/CVaR risk objectives, it cannot be used with VaR and other downside risk measures. As such, I have opted to use the random portfolios method for optimization. The number of permutations of random portfolios satisfying the portfolio constraints and objectives may be a problem if a small number of permutation is chosen, and may not allow for satisfactory comparison across portfolios. To run a very large number of permutations require time and computing power.

Create random portfolios satisfying the above constraints:

```{r random portfolios}
set.seed(1009)

randport <- random_portfolios(portfolio = init_spec, 
                              permutations = 15000, 
                              rp_method = "sample")

dim(randport) # 14999 random portfolios found
```

With the random portfolios, I created a foreach loop to find the daily returns of each random portfolio in `randport`. To speed things up, I ran the **`foreach`** loop in parallel.

Calculate portfolio returns of every weight composition in `randport`:

```{r random portfolios returns, warning=FALSE, message=FALSE}
start_loop <- proc.time()

# Important to make sure that we do not use all cores for computation. Check with detectCores(logical = F)
mycluster <- makeCluster(6) # Number of cores to use. I have 8, but may not be suitable for everyone.

registerDoParallel(mycluster) # Register parallel computing

output1 <- foreach(i = 1:nrow(randport), .combine = "cbind") %dopar% {
  
  rp_return <- PerformanceAnalytics::Return.portfolio(R = returns, 
                                                      weights = randport[i,], 
                                                      geometric = T, 
                                                      rebalance_on = "quarters")
  
  }

stopCluster(mycluster) # End parallel computing

total_time <- proc.time() - start_loop

total_time

dim(output1)
```

We can see that there are 3123 rows and 14999 columns, corresponding to number of observations in `returns` and number of random portfolios in `randport` respectively. The `total_time` shows the time taken to calculate the 14,999 random portfolio returns. The time elapsed was about 580 seconds for the loop.

### 5.1 Minimum Variance Portfolio

With the daily returns of every random portfolio in `output1`, we can calculate the standard deviation and find the minimum to obtain the minimum variance portfolio.

Optimize portfolio based on minimum variance:

```{r minimize standard deviation}
stddev_search <- PerformanceAnalytics::StdDev(R = output1, portfolio_method = "single")

min(stddev_search)

weight_MinVar <- randport[which.min(stddev_search),]

weight_MinVar
```

### 5.2 Minimum Semi-Deviation Portfolio

Optimize portfolio based on minimum semi-deviation:

```{r minimize semi-deviation}
semidev_search <- PerformanceAnalytics::SemiDeviation(R = output1)

min(semidev_search)

weight_MinSemiDev <- randport[which.min(semidev_search),]

weight_MinSemiDev
```

### 5.3 Minimum Downside Deviation Portfolio

Optimize portfolio based on minimum downside deviation:

```{r minimize downside deviation}
downdev_search <- PerformanceAnalytics::DownsideDeviation(R = output1, MAR = 0.03/252)

min(downdev_search)

weight_MinDD <- randport[which.min(downdev_search),]

weight_MinDD
```

### 5.4 Minimum Value-at-Risk Portfolio

For VaR, I would use the historical VaR, although one could experiment with other VaR methods. Since the VaR measure is negative, we want to find the highest negative measure (i.e. closer to or more than 0). If VaR was framed as a positive measure, we would simply minimize the VaR.

Optimize portfolio based on minimum historical VaR:

```{r optimize min_var portfolio}
hvar_search <- PerformanceAnalytics::VaR(R = output1, p = 0.95, method = "historical")

max(hvar_search)

weight_MinHVaR <- randport[which.max(hvar_search),]

weight_MinHVaR
```

### 5.5 Minimum Conditional Value-at-Risk Portfolio

Similar to the VaR portfolio optimization, I would use the historical CVaR.

Optimize portfolio based on minimum historical CVaR:

```{r optimize min_var portfolio}
hcvar_search <- PerformanceAnalytics::CVaR(R = output1, p = 0.95, method = "historical")

max(hcvar_search)

weight_MinHCVaR <- randport[which.max(hcvar_search),]

weight_MinHCVaR
``` 

### 5.6 Summary of Minimum Risk Portfolios

Now that we have created the different portfolios by minimizing different risk measures, we can compare the weights of their components, their performance and chart their cumulative returns.

```{r weights of minimum risk portfolios}
port_weights <- rbind(Min_Var = weight_MinVar, 
                      Min_SemiDev = weight_MinSemiDev, 
                      Min_DownDev = weight_MinDD, 
                      Min_HVaR = weight_MinHVaR, 
                      Min_HCVaR = weight_MinHCVaR)

port_weights
```

Weights of `Min_Var` and `Min_DownDev` portfolios are equal, which would yield equal cumulative returns and performance metrics.

Since we have calculated the daily returns of each portfolio in `output1`, we can extract it and save it into a suitable data frame.

```{r extract daily returns of portfolios}
return_comp <- cbind(output1[, which.min(stddev_search)],
                     output1[, which.min(semidev_search)],
                     output1[, which.min(downdev_search)],
                     output1[, which.max(hvar_search)],
                     output1[, which.max(hcvar_search)]) %>%
  `colnames<-`(c("Min_Var", "Min_SemiDev", "Min_DownDev", "Min_HVaR", "Min_HCVaR"))

head(return_comp)
```

An appropriate benchmark would be needed if we wish to properly compare the performance of our portfolios. I am using the Vanguard Total World Stock ETF as a benchmark, which consists of global equities, although a large amount of the funds is invested in North America.

```{r benchmark return}
benchmark <- quantmod::getSymbols(Symbols = "VT",
                                  src = "yahoo", 
                                  from = startdate, to = enddate, 
                                  periodicity = "daily", 
                                  auto.assign = F)[,6]

benchmark_return <- na.omit(PerformanceAnalytics::Return.calculate(prices = benchmark, method = "discrete"))

head(benchmark_return); dim(benchmark_return)
```

After compiling the returns, we can plot their cumulative returns using **`chart.CumReturns`** and compare their drawdowns by using 

```{r plot performance chart of minimum risk portfolios, fig.align='center'}
PerformanceAnalytics::chart.CumReturns(R = cbind(return_comp, benchmark_return), 
                                       geometric = T, # Use geometric returns since we have arithmetic returns
                                       legend.loc = "topleft",
                                       main = "Cumulative Returns of Minimum Risk Portfolios")

PerformanceAnalytics::chart.Drawdown(R = cbind(return_comp, benchmark_return), 
                                     geometric = T,
                                     legend.loc = "bottomleft",
                                     main = "Drawdown of Minimum Risk Portfolios")
```

Since the `Min_Var` and `Min_DownDev` portfolios have the same weights, they overlapped one another on the charts and we can only see the `Min_Var` cumulative returns and drawdown charts. The `Min_Var` and `Min_DownDev` portfolios performed similarly to the benchmark in cumulative returns. The `Min_SemiDev`, `Min_HVaR` and `Min_HCVaR` portfolios have lesser cumulative returns. The benchmark has generally higher drawdowns than the minimum risk portfolios.

```{r stats and annualized metrics of minimum risk portfolios}
table.AnnualizedReturns(R = cbind(return_comp, benchmark_return), scale = 252, Rf = 0.02/252, geometric = T, digits = 4)

table.Stats(R = cbind(return_comp, benchmark_return), digits = 4)

table.CAPM(Ra = return_comp, Rb = benchmark_return, scale = 252, Rf = 0.02/252, digits = 4)

table.DownsideRisk(R = cbind(return_comp, benchmark_return), scale = 252, Rf = 0.02/252, MAR = 0.03/252, digits = 4)
```

## 6 Optimal Portfolio Selection With Target Return

In this section, I optimized portfolios based on a target return of 20% annually. Since we have generated random portfolios in Section 5, I used that to determine the subset of portfolios that meets the target return requirement. Reason for doing this is that the permutations of random portfolios in Section 5 is not the entire sample that meets the weight sum and box constraints. Unless we use a different seed, the newly generated random portfolios with target return constraint will likely be the same as in Section 5 due to the limited permutations.

Since the target return is 20% annually, I calculated the average annualized return and subset the portfolios that meet the constraint.

```{r subset of randport with target return}
mycluster <- makeCluster(6)

registerDoParallel(mycluster)

rp_annreturn <- foreach(i = 1:ncol(output1), .combine = "rbind") %dopar% {
  
  PerformanceAnalytics::Return.annualized(R = output1[, i], scale = 252, geometric = T)
  
  }

stopCluster(mycluster)

subrp_return <- rp_annreturn > 0.08 # relaxing the constraints a little to capture sufficient portfolios
```

```{r}
meanrisk_spec <- add.constraint(portfolio = init_spec, type = "return", return_target = 0.2/252)

set.seed(10)

randport2 <- random_portfolios(portfolio = meanrisk_spec, 
                               permutations = 15000, 
                               rp_method = "sample")

dim(randport2)
```












```{r}
meanvar_search <- PerformanceAnalytics::StdDev(R = output2, portfolio_method = "single")

min(meanvar_search)

weight_MeanVar <- randport2[which.min(meanvar_search), ]

weight_MeanVar
```



```{r}
test_spec <- add.objective(portfolio = meanrisk_spec, type = "return", name = "mean")

test_spec <- add.objective(portfolio = test_spec, type = "risk", name = "var")

registerDoSEQ()

optimize.portfolio(R = returns, portfolio = meanrisk_spec, optimize_method = "random", search_size = 40000)
```




























## References

<https://analystprep.com/study-notes/frm/part-1/valuation-and-risk-management/measures-of-financial-risk/>

<https://corporatefinanceinstitute.com/resources/knowledge/trading-investing/value-at-risk-var/>

<https://www.financialplanningassociation.org/article/journal/JUN13-intuitive-examination-downside-risk>

<https://www.investopedia.com/terms/s/semideviation.asp>

<https://pages.stern.nyu.edu/~adamodar/pdfiles/valrisk/ch4.pdf>






